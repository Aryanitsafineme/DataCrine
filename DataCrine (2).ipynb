{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8dba3da-66d2-48b2-811d-1041db385a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.13-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: ucimlrepo in c:\\users\\aryan\\anaconda3\\lib\\site-packages (0.0.7)\n",
      "Requirement already satisfied: packaging in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from kagglehub) (24.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from kagglehub) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from kagglehub) (4.66.5)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from ucimlrepo) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from ucimlrepo) (2025.4.26)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from requests->kagglehub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from requests->kagglehub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2.2.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
      "Downloading kagglehub-0.3.13-py3-none-any.whl (68 kB)\n",
      "Installing collected packages: kagglehub\n",
      "Successfully installed kagglehub-0.3.13\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub ucimlrepo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1b66172-aaab-4835-a218-dae5247428f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25.7M/25.7M [00:02<00:00, 9.39MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Dataset path: C:\\Users\\aryan\\.cache\\kagglehub\\datasets\\lakshmi25npathi\\imdb-dataset-of-50k-movie-reviews\\versions\\1\n",
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "\n",
    "# Download dataset\n",
    "path = kagglehub.dataset_download(\"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\")\n",
    "print(\"Dataset path:\", path)\n",
    "\n",
    "# Load IMDb data\n",
    "imdb = pd.read_csv(f\"{path}/IMDB Dataset.csv\")\n",
    "print(imdb.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "201a75cb-ae19-41f1-a301-5abf6a3c34a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       X1  X2  X3  X4  X5  X6  X7  X8  X9  X10  ...    X15    X16    X17  \\\n",
      "0   20000   2   2   1  24   2   2  -1  -1   -2  ...      0      0      0   \n",
      "1  120000   2   2   2  26  -1   2   0   0    0  ...   3272   3455   3261   \n",
      "2   90000   2   2   2  34   0   0   0   0    0  ...  14331  14948  15549   \n",
      "3   50000   2   2   1  37   0   0   0   0    0  ...  28314  28959  29547   \n",
      "4   50000   1   2   1  57  -1   0  -1   0    0  ...  20940  19146  19131   \n",
      "\n",
      "    X18    X19    X20   X21   X22   X23  Y  \n",
      "0     0    689      0     0     0     0  1  \n",
      "1     0   1000   1000  1000     0  2000  1  \n",
      "2  1518   1500   1000  1000  1000  5000  0  \n",
      "3  2000   2019   1200  1100  1069  1000  0  \n",
      "4  2000  36681  10000  9000   689   679  0  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# Fetch dataset (ID 350 = Credit Default)\n",
    "credit_data = fetch_ucirepo(id=350)\n",
    "\n",
    "X = credit_data.data.features\n",
    "y = credit_data.data.targets\n",
    "\n",
    "uci_credit = pd.concat([X, y], axis=1)\n",
    "print(uci_credit.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c527cae-8c79-4a66-833c-27697083b45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "361583a5-3357-4afe-af38-d99597bd63b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_numeric_mean(df: pd.DataFrame, cols):\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].fillna(df[c].mean())\n",
    "    return df\n",
    "\n",
    "def cap_outliers_iqr(df: pd.DataFrame, cols, k=1.5):\n",
    "    for c in cols:\n",
    "        if c in df.columns and pd.api.types.is_numeric_dtype(df[c]):\n",
    "            q1, q3 = df[c].quantile(0.25), df[c].quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "            low, high = q1 - k*iqr, q3 + k*iqr\n",
    "            df[c] = df[c].clip(lower=low, upper=high)\n",
    "    return df\n",
    "\n",
    "def drop_dupes(df: pd.DataFrame, subset=None):\n",
    "    return df.drop_duplicates(subset=subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cc643f9-04ac-4d19-9c91-89eba379c2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# small local Hugging Face model for IMDb sentiment\n",
    "sentiment_pipe = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")\n",
    "\n",
    "def imdb_label_check(df: pd.DataFrame, text_col=\"review\", label_col=\"sentiment\"):\n",
    "    \"\"\"\n",
    "    Compare IMDb dataset labels with DistilBERT local sentiment prediction.\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for txt in df[text_col].astype(str).fillna(\"\"):\n",
    "        out.append(sentiment_pipe(txt[:512])[0][\"label\"].lower())  # positive / negative\n",
    "    df[\"llm_sentiment\"] = out\n",
    "\n",
    "    flags, rats = [], []\n",
    "    for _, r in df.iterrows():\n",
    "        gold = str(r[label_col]).lower()\n",
    "        pred = r[\"llm_sentiment\"]\n",
    "        if gold.startswith(\"pos\") and pred == \"negative\":\n",
    "            flags.append(True)\n",
    "            rats.append(\"Mismatch: labeled POS but text looks NEG.\")\n",
    "        elif gold.startswith(\"neg\") and pred == \"positive\":\n",
    "            flags.append(True)\n",
    "            rats.append(\"Mismatch: labeled NEG but text looks POS.\")\n",
    "        else:\n",
    "            flags.append(False)\n",
    "            rats.append(\"Aligned with sentiment.\")\n",
    "    df[\"llm_flag\"] = flags\n",
    "    df[\"llm_rationale\"] = rats\n",
    "    return df\n",
    "\n",
    "def uci_semantic_rules(df, limit_col=\"LIMIT_BAL\", age_col=\"AGE\"):\n",
    "    \"\"\"\n",
    "    Apply domain rules on UCI Credit dataset for plausibility checks.\n",
    "    \"\"\"\n",
    "    flags, reasons = [], []\n",
    "    for _, r in df.iterrows():\n",
    "        msg = []\n",
    "        if r[limit_col] > 1_000_000:\n",
    "            msg.append(\"Unrealistic credit limit (>1,000,000).\")\n",
    "        if r[age_col] < 18:\n",
    "            msg.append(\"Invalid age (<18).\")\n",
    "        if msg:\n",
    "            flags.append(True)\n",
    "            reasons.append(\"; \".join(msg))\n",
    "        else:\n",
    "            flags.append(False)\n",
    "            reasons.append(\"No issues detected.\")\n",
    "    df[\"llm_flag\"] = flags\n",
    "    df[\"llm_rationale\"] = reasons\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ac07a48-a6c5-4b12-af5c-4cae1a97ee20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== IMDb sample run ===\n",
      "                                                  review sentiment  \\\n",
      "33553  I really liked this Summerslam due to the look...  positive   \n",
      "9427   Not many television shows appeal to quite as m...  positive   \n",
      "199    The film quickly gets to a major chase scene w...  negative   \n",
      "12447  Jane Austen would definitely approve of this o...  positive   \n",
      "39489  Expectations were somewhat high for me when I ...  negative   \n",
      "\n",
      "      llm_sentiment  llm_flag                              llm_rationale  \n",
      "33553      positive     False                    Aligned with sentiment.  \n",
      "9427       positive     False                    Aligned with sentiment.  \n",
      "199        negative     False                    Aligned with sentiment.  \n",
      "12447      positive     False                    Aligned with sentiment.  \n",
      "39489      positive      True  Mismatch: labeled NEG but text looks POS.  \n"
     ]
    }
   ],
   "source": [
    "print(\"=== IMDb sample run ===\")\n",
    "sample_imdb = imdb.sample(5, random_state=42).copy()\n",
    "sample_imdb = imdb_label_check(sample_imdb, text_col=\"review\", label_col=\"sentiment\")\n",
    "print(sample_imdb[[\"review\", \"sentiment\", \"llm_sentiment\", \"llm_flag\", \"llm_rationale\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2ad8cd0-26ef-4afb-8f52-7331f091f6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X20', 'X21', 'X22', 'X23', 'Y']\n"
     ]
    }
   ],
   "source": [
    "print(uci_credit.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99277bfd-25c8-4537-9e88-73f50bb2c5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uci_semantic_rules(df):\n",
    "    \"\"\"\n",
    "    Apply domain checks to UCI Credit dataset (X1=LIMIT_BAL, X5=AGE).\n",
    "    \"\"\"\n",
    "    flags, reasons = [], []\n",
    "    for _, r in df.iterrows():\n",
    "        msg = []\n",
    "        # Credit limit plausibility\n",
    "        if pd.notna(r[\"X1\"]) and r[\"X1\"] > 1_000_000:\n",
    "            msg.append(\"Unrealistic credit limit (>1,000,000).\")\n",
    "        if pd.notna(r[\"X1\"]) and r[\"X1\"] <= 0:\n",
    "            msg.append(\"Invalid credit limit (<=0).\")\n",
    "\n",
    "        # Age plausibility\n",
    "        if pd.notna(r[\"X5\"]) and r[\"X5\"] < 18:\n",
    "            msg.append(\"Invalid age (<18).\")\n",
    "        if pd.notna(r[\"X5\"]) and r[\"X5\"] > 100:\n",
    "            msg.append(\"Unrealistic age (>100).\")\n",
    "\n",
    "        if msg:\n",
    "            flags.append(True)\n",
    "            reasons.append(\"; \".join(msg))\n",
    "        else:\n",
    "            flags.append(False)\n",
    "            reasons.append(\"No issues detected.\")\n",
    "    df[\"llm_flag\"] = flags\n",
    "    df[\"llm_rationale\"] = reasons\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af177ada-0aee-4922-884b-93d4dcd01a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== UCI Credit sample run ===\n",
      "           X1  X5  llm_flag        llm_rationale\n",
      "2308    30000  25     False  No issues detected.\n",
      "22404  150000  26     False  No issues detected.\n",
      "23397   70000  32     False  No issues detected.\n",
      "25058  130000  49     False  No issues detected.\n",
      "2664    50000  36     False  No issues detected.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== UCI Credit sample run ===\")\n",
    "sample_uci = uci_credit.sample(5, random_state=42).copy()\n",
    "\n",
    "# Traditional cleaning\n",
    "sample_uci = impute_numeric_mean(sample_uci, [\"X5\"])   # AGE\n",
    "sample_uci = cap_outliers_iqr(sample_uci, [\"X1\"])      # LIMIT_BAL\n",
    "\n",
    "# Semantic checks\n",
    "sample_uci = uci_semantic_rules(sample_uci)\n",
    "\n",
    "print(sample_uci[[\"X1\", \"X5\", \"llm_flag\", \"llm_rationale\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c02a5333-7e99-4304-9744-5af456091768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(dataset=\"uci\", n=5):\n",
    "    \"\"\"\n",
    "    Run Datacrine pipeline on either IMDb or UCI dataset.\n",
    "    dataset: \"uci\" or \"imdb\"\n",
    "    n: number of sample rows to show\n",
    "    \"\"\"\n",
    "    if dataset.lower() == \"imdb\":\n",
    "        print(\"\\n=== Running Datacrine on IMDb Dataset ===\")\n",
    "        df = imdb.sample(n, random_state=42).copy()\n",
    "        df = imdb_label_check(df, text_col=\"review\", label_col=\"sentiment\")\n",
    "        display_cols = [\"review\", \"sentiment\", \"llm_sentiment\", \"llm_flag\", \"llm_rationale\"]\n",
    "    \n",
    "    elif dataset.lower() == \"uci\":\n",
    "        print(\"\\n=== Running Datacrine on UCI Credit Dataset ===\")\n",
    "        df = uci_credit.sample(n, random_state=42).copy()\n",
    "        df = impute_numeric_mean(df, [\"X5\"])   # AGE\n",
    "        df = cap_outliers_iqr(df, [\"X1\"])      # LIMIT_BAL\n",
    "        df = uci_semantic_rules(df)            # semantic checks\n",
    "        display_cols = [\"X1\", \"X5\", \"llm_flag\", \"llm_rationale\"]\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Dataset must be 'uci' or 'imdb'\")\n",
    "    \n",
    "    return df[display_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69a94778-751e-4ef8-a5e9-3df2b2690160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Datacrine on IMDb Dataset ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>llm_sentiment</th>\n",
       "      <th>llm_flag</th>\n",
       "      <th>llm_rationale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33553</th>\n",
       "      <td>I really liked this Summerslam due to the look...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "      <td>Aligned with sentiment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9427</th>\n",
       "      <td>Not many television shows appeal to quite as m...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "      <td>Aligned with sentiment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>The film quickly gets to a major chase scene w...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>Aligned with sentiment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12447</th>\n",
       "      <td>Jane Austen would definitely approve of this o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "      <td>Aligned with sentiment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39489</th>\n",
       "      <td>Expectations were somewhat high for me when I ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "      <td>Mismatch: labeled NEG but text looks POS.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  \\\n",
       "33553  I really liked this Summerslam due to the look...  positive   \n",
       "9427   Not many television shows appeal to quite as m...  positive   \n",
       "199    The film quickly gets to a major chase scene w...  negative   \n",
       "12447  Jane Austen would definitely approve of this o...  positive   \n",
       "39489  Expectations were somewhat high for me when I ...  negative   \n",
       "\n",
       "      llm_sentiment  llm_flag                              llm_rationale  \n",
       "33553      positive     False                    Aligned with sentiment.  \n",
       "9427       positive     False                    Aligned with sentiment.  \n",
       "199        negative     False                    Aligned with sentiment.  \n",
       "12447      positive     False                    Aligned with sentiment.  \n",
       "39489      positive      True  Mismatch: labeled NEG but text looks POS.  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_pipeline(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7314ae47-2f58-479a-b29c-6e2570691c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Datacrine on UCI Credit Dataset ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X5</th>\n",
       "      <th>llm_flag</th>\n",
       "      <th>llm_rationale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2308</th>\n",
       "      <td>30000</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>No issues detected.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22404</th>\n",
       "      <td>150000</td>\n",
       "      <td>26</td>\n",
       "      <td>False</td>\n",
       "      <td>No issues detected.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23397</th>\n",
       "      <td>70000</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>No issues detected.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25058</th>\n",
       "      <td>130000</td>\n",
       "      <td>49</td>\n",
       "      <td>False</td>\n",
       "      <td>No issues detected.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2664</th>\n",
       "      <td>50000</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "      <td>No issues detected.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           X1  X5  llm_flag        llm_rationale\n",
       "2308    30000  25     False  No issues detected.\n",
       "22404  150000  26     False  No issues detected.\n",
       "23397   70000  32     False  No issues detected.\n",
       "25058  130000  49     False  No issues detected.\n",
       "2664    50000  36     False  No issues detected."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_pipeline(\"uci\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9b4db1e-76f2-4d0f-89fb-cdd2c87ecbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_flags(df):\n",
    "    if \"llm_flag\" not in df.columns:\n",
    "        print(\"⚠️ No llm_flag column found. Did you run the pipeline?\")\n",
    "        return\n",
    "    total = len(df)\n",
    "    flagged = df[\"llm_flag\"].sum()\n",
    "    pct = (flagged / total) * 100 if total > 0 else 0\n",
    "    print(f\"{total} rows checked, {flagged} flagged ({pct:.1f}% anomalies detected)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3da56968-8560-489a-b9ab-11af86eb7cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Datacrine on UCI Credit Dataset ===\n",
      "           X1  X5  llm_flag        llm_rationale\n",
      "2308    30000  25     False  No issues detected.\n",
      "22404  150000  26     False  No issues detected.\n",
      "23397   70000  32     False  No issues detected.\n",
      "25058  130000  49     False  No issues detected.\n",
      "2664    50000  36     False  No issues detected.\n",
      "8511    50000  29     False  No issues detected.\n",
      "5148   110000  33     False  No issues detected.\n",
      "7790   140000  32     False  No issues detected.\n",
      "11311  256250  38     False  No issues detected.\n",
      "19043   80000  23     False  No issues detected.\n",
      "10784   80000  33     False  No issues detected.\n",
      "22246   90000  25     False  No issues detected.\n",
      "3268    80000  34     False  No issues detected.\n",
      "15947   30000  30     False  No issues detected.\n",
      "14977  200000  29     False  No issues detected.\n",
      "14474  110000  39     False  No issues detected.\n",
      "28694  100000  33     False  No issues detected.\n",
      "14054   30000  51     False  No issues detected.\n",
      "26545  200000  50     False  No issues detected.\n",
      "14980   30000  23     False  No issues detected.\n",
      "20 rows checked, 0 flagged (0.0% anomalies detected)\n",
      "\n",
      "=== Running Datacrine on IMDb Dataset ===\n",
      "                                                  review sentiment  \\\n",
      "33553  I really liked this Summerslam due to the look...  positive   \n",
      "9427   Not many television shows appeal to quite as m...  positive   \n",
      "199    The film quickly gets to a major chase scene w...  negative   \n",
      "12447  Jane Austen would definitely approve of this o...  positive   \n",
      "39489  Expectations were somewhat high for me when I ...  negative   \n",
      "42724  I've watched this movie on a fairly regular ba...  positive   \n",
      "10822  For once a story of hope highlighted over the ...  positive   \n",
      "49498  Okay, I didn't get the Purgatory thing the fir...  positive   \n",
      "4144   I was very disappointed with this series. It h...  negative   \n",
      "36958  The first 30 minutes of Tinseltown had my fing...  negative   \n",
      "43106  jeez, this was immensely boring. the leading m...  negative   \n",
      "38695  Great just great! The West Coast got \"Dirty\" H...  positive   \n",
      "6188   It's made in 2007 and the CG is bad for a movi...  negative   \n",
      "1414   This movie stinks majorly. The only reason I g...  negative   \n",
      "18471  We can start with the wooden acting but this f...  negative   \n",
      "29282  This movie starts off somewhat slowly and gets...  positive   \n",
      "15177  This is a slightly uneven entry with one stand...  positive   \n",
      "34304  I was first introduced to John Waters films by...  positive   \n",
      "12609  This movie has very good acting by virtually a...  positive   \n",
      "12144  I can't help but notice the negative reviews t...  positive   \n",
      "\n",
      "      llm_sentiment  llm_flag                              llm_rationale  \n",
      "33553      positive     False                    Aligned with sentiment.  \n",
      "9427       positive     False                    Aligned with sentiment.  \n",
      "199        negative     False                    Aligned with sentiment.  \n",
      "12447      positive     False                    Aligned with sentiment.  \n",
      "39489      positive      True  Mismatch: labeled NEG but text looks POS.  \n",
      "42724      positive     False                    Aligned with sentiment.  \n",
      "10822      positive     False                    Aligned with sentiment.  \n",
      "49498      positive     False                    Aligned with sentiment.  \n",
      "4144       negative     False                    Aligned with sentiment.  \n",
      "36958      negative     False                    Aligned with sentiment.  \n",
      "43106      negative     False                    Aligned with sentiment.  \n",
      "38695      positive     False                    Aligned with sentiment.  \n",
      "6188       negative     False                    Aligned with sentiment.  \n",
      "1414       negative     False                    Aligned with sentiment.  \n",
      "18471      negative     False                    Aligned with sentiment.  \n",
      "29282      positive     False                    Aligned with sentiment.  \n",
      "15177      negative      True  Mismatch: labeled POS but text looks NEG.  \n",
      "34304      negative      True  Mismatch: labeled POS but text looks NEG.  \n",
      "12609      positive     False                    Aligned with sentiment.  \n",
      "12144      positive     False                    Aligned with sentiment.  \n",
      "20 rows checked, 3 flagged (15.0% anomalies detected)\n"
     ]
    }
   ],
   "source": [
    "result_uci = run_pipeline(\"uci\", n=20)\n",
    "print(result_uci)\n",
    "summarize_flags(result_uci)\n",
    "\n",
    "result_imdb = run_pipeline(\"imdb\", n=20)\n",
    "print(result_imdb)\n",
    "summarize_flags(result_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d35fb6ec-3291-4656-ae8a-c720a8af62a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_cleaned_data(df, dataset=\"uci\"):\n",
    "    \"\"\"\n",
    "    Save cleaned dataset to disk in data/cleaned folder.\n",
    "    \"\"\"\n",
    "    os.makedirs(\"data/cleaned\", exist_ok=True)\n",
    "    path = f\"data/cleaned/{dataset}_cleaned.csv\"\n",
    "    df.to_csv(path, index=False)\n",
    "    print(f\"✅ Cleaned {dataset} dataset saved at: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9ba968e-6c13-4666-b209-ef3241f0e0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Datacrine on UCI Credit Dataset ===\n",
      "2000 rows checked, 0 flagged (0.0% anomalies detected)\n",
      "✅ Cleaned uci dataset saved at: data/cleaned/uci_cleaned.csv\n",
      "\n",
      "=== Running Datacrine on IMDb Dataset ===\n",
      "2000 rows checked, 370 flagged (18.5% anomalies detected)\n",
      "✅ Cleaned imdb dataset saved at: data/cleaned/imdb_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# Run on UCI and save\n",
    "uci_result = run_pipeline(\"uci\", n=2000)  # larger sample, or use full dataset later\n",
    "summarize_flags(uci_result)\n",
    "save_cleaned_data(uci_result, \"uci\")\n",
    "\n",
    "# Run on IMDb and save\n",
    "imdb_result = run_pipeline(\"imdb\", n=2000)\n",
    "summarize_flags(imdb_result)\n",
    "save_cleaned_data(imdb_result, \"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1d9e5c2-c089-4d37-a583-8ff5735e81a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\aryan\\anaconda3\\lib\\site-packages (3.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\aryan\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "146a601a-1cdb-47fc-8945-f6b2a3e787c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "def train_and_evaluate(df, dataset=\"uci\", target_col=\"Y\"):\n",
    "    \"\"\"\n",
    "    Train Random Forest & XGBoost on dataset and report accuracy/F1.\n",
    "    Works for UCI (classification). For IMDb, we'll map sentiment to 0/1.\n",
    "    \"\"\"\n",
    "    # Prepare data\n",
    "    if dataset == \"uci\":\n",
    "        X = df.drop(columns=[target_col, \"llm_flag\", \"llm_rationale\"], errors=\"ignore\")\n",
    "        y = df[target_col]\n",
    "    elif dataset == \"imdb\":\n",
    "        df = df.copy()\n",
    "        df[\"label_num\"] = df[\"sentiment\"].map({\"positive\": 1, \"negative\": 0})\n",
    "        X = df[\"review\"]  # text input\n",
    "        y = df[\"label_num\"]\n",
    "        # Convert text → TF-IDF for classical models\n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        vectorizer = TfidfVectorizer(max_features=5000, stop_words=\"english\")\n",
    "        X = vectorizer.fit_transform(X)\n",
    "    else:\n",
    "        raise ValueError(\"Dataset must be 'uci' or 'imdb'\")\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    preds_rf = rf.predict(X_test)\n",
    "    results[\"RandomForest\"] = {\n",
    "        \"Accuracy\": accuracy_score(y_test, preds_rf),\n",
    "        \"F1\": f1_score(y_test, preds_rf)\n",
    "    }\n",
    "\n",
    "    # XGBoost\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=6,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=42\n",
    "    )\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    preds_xgb = xgb_model.predict(X_test)\n",
    "    results[\"XGBoost\"] = {\n",
    "        \"Accuracy\": accuracy_score(y_test, preds_xgb),\n",
    "        \"F1\": f1_score(y_test, preds_xgb)\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62c4606f-d6e6-4664-9ba2-0c33bf449d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       X1  X2  X3  X4  X5  X6  X7  X8  X9  X10  ...    X15    X16    X17  \\\n",
      "0   20000   2   2   1  24   2   2  -1  -1   -2  ...      0      0      0   \n",
      "1  120000   2   2   2  26  -1   2   0   0    0  ...   3272   3455   3261   \n",
      "2   90000   2   2   2  34   0   0   0   0    0  ...  14331  14948  15549   \n",
      "3   50000   2   2   1  37   0   0   0   0    0  ...  28314  28959  29547   \n",
      "4   50000   1   2   1  57  -1   0  -1   0    0  ...  20940  19146  19131   \n",
      "\n",
      "    X18    X19    X20   X21   X22   X23  Y  \n",
      "0     0    689      0     0     0     0  1  \n",
      "1     0   1000   1000  1000     0  2000  1  \n",
      "2  1518   1500   1000  1000  1000  5000  0  \n",
      "3  2000   2019   1200  1100  1069  1000  0  \n",
      "4  2000  36681  10000  9000   689   679  0  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "# fetch dataset (ID 350 = Credit Default)\n",
    "credit_data = fetch_ucirepo(id=350)\n",
    "\n",
    "X = credit_data.data.features\n",
    "y = credit_data.data.targets\n",
    "\n",
    "uci_credit = pd.concat([X, y], axis=1)\n",
    "print(uci_credit.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18a0a48e-a875-445d-8018-ede17e09cf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aryan\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:28:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCI Raw Results: {'RandomForest': {'Accuracy': 0.8123333333333334, 'F1': 0.46227316141356256}, 'XGBoost': {'Accuracy': 0.8136666666666666, 'F1': 0.4599033816425121}}\n"
     ]
    }
   ],
   "source": [
    "uci_raw_results = train_and_evaluate(uci_credit, dataset=\"uci\", target_col=\"Y\")\n",
    "print(\"UCI Raw Results:\", uci_raw_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6e7fadb-90ed-4642-854d-59684956231e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# === MASTER INIT FOR DATACRINE ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import kagglehub\n",
    "\n",
    "# -------------------------------\n",
    "# Load datasets\n",
    "# -------------------------------\n",
    "# IMDb\n",
    "path = kagglehub.dataset_download(\"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\")\n",
    "imdb = pd.read_csv(f\"{path}/IMDB Dataset.csv\")\n",
    "\n",
    "# UCI Credit\n",
    "credit_data = fetch_ucirepo(id=350)\n",
    "X = credit_data.data.features\n",
    "y = credit_data.data.targets\n",
    "uci_credit = pd.concat([X, y], axis=1)\n",
    "\n",
    "# -------------------------------\n",
    "# Cleaning functions\n",
    "# -------------------------------\n",
    "def impute_numeric_mean(df: pd.DataFrame, cols):\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].fillna(df[c].mean())\n",
    "    return df\n",
    "\n",
    "def cap_outliers_iqr(df: pd.DataFrame, cols, k=1.5):\n",
    "    for c in cols:\n",
    "        if c in df.columns and pd.api.types.is_numeric_dtype(df[c]):\n",
    "            q1, q3 = df[c].quantile(0.25), df[c].quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "            low, high = q1 - k*iqr, q3 + k*iqr\n",
    "            df[c] = df[c].clip(lower=low, upper=high)\n",
    "    return df\n",
    "\n",
    "# -------------------------------\n",
    "# Semantic / LLM functions\n",
    "# -------------------------------\n",
    "sentiment_pipe = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")\n",
    "\n",
    "def imdb_label_check(df: pd.DataFrame, text_col=\"review\", label_col=\"sentiment\"):\n",
    "    out = []\n",
    "    for txt in df[text_col].astype(str).fillna(\"\"):\n",
    "        out.append(sentiment_pipe(txt[:512])[0][\"label\"].lower())\n",
    "    df[\"llm_sentiment\"] = out\n",
    "\n",
    "    flags, rats = [], []\n",
    "    for _, r in df.iterrows():\n",
    "        gold = str(r[label_col]).lower()\n",
    "        pred = r[\"llm_sentiment\"]\n",
    "        if gold.startswith(\"pos\") and pred == \"negative\":\n",
    "            flags.append(True); rats.append(\"Mismatch: labeled POS but looks NEG.\")\n",
    "        elif gold.startswith(\"neg\") and pred == \"positive\":\n",
    "            flags.append(True); rats.append(\"Mismatch: labeled NEG but looks POS.\")\n",
    "        else:\n",
    "            flags.append(False); rats.append(\"Aligned with sentiment.\")\n",
    "    df[\"llm_flag\"] = flags\n",
    "    df[\"llm_rationale\"] = rats\n",
    "    return df\n",
    "\n",
    "def uci_semantic_rules(df):\n",
    "    flags, reasons = [], []\n",
    "    for _, r in df.iterrows():\n",
    "        msg = []\n",
    "        if pd.notna(r[\"X1\"]) and r[\"X1\"] > 1_000_000:\n",
    "            msg.append(\"Unrealistic credit limit (>1,000,000).\")\n",
    "        if pd.notna(r[\"X1\"]) and r[\"X1\"] <= 0:\n",
    "            msg.append(\"Invalid credit limit (<=0).\")\n",
    "        if pd.notna(r[\"X5\"]) and r[\"X5\"] < 18:\n",
    "            msg.append(\"Invalid age (<18).\")\n",
    "        if pd.notna(r[\"X5\"]) and r[\"X5\"] > 100:\n",
    "            msg.append(\"Unrealistic age (>100).\")\n",
    "        if msg:\n",
    "            flags.append(True); reasons.append(\"; \".join(msg))\n",
    "        else:\n",
    "            flags.append(False); reasons.append(\"No issues detected.\")\n",
    "    df[\"llm_flag\"] = flags\n",
    "    df[\"llm_rationale\"] = reasons\n",
    "    return df\n",
    "\n",
    "# -------------------------------\n",
    "# Unified pipeline\n",
    "# -------------------------------\n",
    "def run_pipeline(dataset=\"uci\", n=5):\n",
    "    if dataset.lower() == \"imdb\":\n",
    "        print(\"\\n=== Running Datacrine on IMDb Dataset ===\")\n",
    "        df = imdb.sample(n, random_state=42).copy()\n",
    "        df = imdb_label_check(df, text_col=\"review\", label_col=\"sentiment\")\n",
    "        display_cols = [\"review\", \"sentiment\", \"llm_sentiment\", \"llm_flag\", \"llm_rationale\"]\n",
    "    elif dataset.lower() == \"uci\":\n",
    "        print(\"\\n=== Running Datacrine on UCI Credit Dataset ===\")\n",
    "        df = uci_credit.sample(n, random_state=42).copy()\n",
    "        df = impute_numeric_mean(df, [\"X5\"])\n",
    "        df = cap_outliers_iqr(df, [\"X1\"])\n",
    "        df = uci_semantic_rules(df)\n",
    "        display_cols = [\"X1\", \"X5\", \"llm_flag\", \"llm_rationale\"]\n",
    "    else:\n",
    "        raise ValueError(\"Dataset must be 'uci' or 'imdb'\")\n",
    "    return df[display_cols]\n",
    "\n",
    "# -------------------------------\n",
    "# Summary helper\n",
    "# -------------------------------\n",
    "def summarize_flags(df):\n",
    "    if \"llm_flag\" not in df.columns:\n",
    "        print(\"⚠️ No llm_flag column found. Did you run the pipeline?\")\n",
    "        return\n",
    "    total = len(df)\n",
    "    flagged = df[\"llm_flag\"].sum()\n",
    "    pct = (flagged / total) * 100 if total > 0 else 0\n",
    "    print(f\"{total} rows checked, {flagged} flagged ({pct:.1f}% anomalies detected)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfe45764-9131-46d2-8aa8-b0c116393aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Datacrine on UCI Credit Dataset ===\n",
      "UCI Cleaned Results: {'RandomForest': {'Accuracy': 0.7656666666666667, 'F1': 0.03566529492455418}, 'XGBoost': {'Accuracy': 0.7768333333333334, 'F1': 0.0014914243102162564}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aryan\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:31:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "uci_cleaned = run_pipeline(\"uci\", n=len(uci_credit))\n",
    "uci_cleaned[\"Y\"] = uci_credit[\"Y\"].values\n",
    "uci_clean_results = train_and_evaluate(uci_cleaned, dataset=\"uci\", target_col=\"Y\")\n",
    "print(\"UCI Cleaned Results:\", uci_clean_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21201bfa-9687-42a4-9fc0-b8a6d199c0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aryan\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [12:38:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDb Raw Results: {'RandomForest': {'Accuracy': 0.8586, 'F1': 0.8571428571428571}, 'XGBoost': {'Accuracy': 0.8623, 'F1': 0.8653827353602502}}\n",
      "\n",
      "=== Running Datacrine on IMDb Dataset ===\n"
     ]
    }
   ],
   "source": [
    "# === IMDb Raw vs Cleaned Evaluation ===\n",
    "\n",
    "# Convert sentiment to binary (pos=1, neg=0)\n",
    "imdb_bin = imdb.copy()\n",
    "imdb_bin[\"label\"] = imdb_bin[\"sentiment\"].map({\"positive\": 1, \"negative\": 0})\n",
    "\n",
    "# Raw IMDb evaluation\n",
    "imdb_raw_results = train_and_evaluate(\n",
    "    imdb_bin.rename(columns={\"label\": \"Y\"}), \n",
    "    dataset=\"imdb\", \n",
    "    target_col=\"Y\"\n",
    ")\n",
    "print(\"IMDb Raw Results:\", imdb_raw_results)\n",
    "\n",
    "# Clean IMDb via pipeline\n",
    "imdb_cleaned = run_pipeline(\"imdb\", n=len(imdb_bin))\n",
    "imdb_cleaned[\"Y\"] = imdb_bin[\"label\"].values\n",
    "\n",
    "# Evaluate cleaned IMDb\n",
    "imdb_clean_results = train_and_evaluate(\n",
    "    imdb_cleaned.rename(columns={\"llm_sentiment\": \"Y\"}), \n",
    "    dataset=\"imdb\", \n",
    "    target_col=\"Y\"\n",
    ")\n",
    "print(\"IMDb Cleaned Results:\", imdb_clean_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70994491-6cd0-45a2-b215-2933e47a1c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Collect results\n",
    "datasets = [\"UCI\", \"IMDb\"]\n",
    "models = [\"RandomForest\", \"XGBoost\"]\n",
    "metrics = [\"Accuracy\", \"F1\"]\n",
    "\n",
    "results = {\n",
    "    \"UCI Raw\": uci_raw_results,\n",
    "    \"UCI Cleaned\": uci_clean_results,\n",
    "    \"IMDb Raw\": imdb_raw_results,\n",
    "    \"IMDb Cleaned\": imdb_clean_results\n",
    "}\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax = axes[i]\n",
    "    for model in models:\n",
    "        raw_vals = [results[f\"{ds} Raw\"][model][metric] for ds in datasets]\n",
    "        clean_vals = [results[f\"{ds} Cleaned\"][model][metric] for ds in datasets]\n",
    "        \n",
    "        x = range(len(datasets))\n",
    "        ax.plot(x, raw_vals, marker=\"o\", label=f\"{model} Raw\")\n",
    "        ax.plot(x, clean_vals, marker=\"x\", linestyle=\"--\", label=f\"{model} Cleaned\")\n",
    "    \n",
    "    ax.set_title(metric)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(datasets)\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.legend()\n",
    "\n",
    "plt.suptitle(\"Datacrine: Raw vs Cleaned Performance (UCI & IMDb)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbadcb95-f98f-4a23-8d8b-41a35db5675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "class Datacrine:\n",
    "    def __init__(self):\n",
    "        # Load LLM model once\n",
    "        self.sentiment_pipe = pipeline(\n",
    "            \"sentiment-analysis\",\n",
    "            model=\"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "        )\n",
    "        self.logs = []  # to store cleaning/audit logs\n",
    "\n",
    "    def log(self, message):\n",
    "        \"\"\"Keep track of what Datacrine is doing.\"\"\"\n",
    "        print(message)\n",
    "        self.logs.append(message)\n",
    "\n",
    "    # --- Cleaning Functions ---\n",
    "    def impute_numeric_mean(self, df, cols):\n",
    "        for c in cols:\n",
    "            if c in df.columns:\n",
    "                mean_val = df[c].mean()\n",
    "                df[c] = df[c].fillna(mean_val)\n",
    "                self.log(f\"Imputed missing values in {c} with mean={mean_val:.2f}\")\n",
    "        return df\n",
    "\n",
    "    def cap_outliers_iqr(self, df, cols, k=1.5):\n",
    "        for c in cols:\n",
    "            if c in df.columns and pd.api.types.is_numeric_dtype(df[c]):\n",
    "                q1, q3 = df[c].quantile(0.25), df[c].quantile(0.75)\n",
    "                iqr = q3 - q1\n",
    "                low, high = q1 - k*iqr, q3 + k*iqr\n",
    "                df[c] = df[c].clip(lower=low, upper=high)\n",
    "                self.log(f\"Capped outliers in {c} to [{low:.2f}, {high:.2f}]\")\n",
    "        return df\n",
    "\n",
    "    def uci_semantic_rules(self, df):\n",
    "        flags, reasons = [], []\n",
    "        for _, r in df.iterrows():\n",
    "            msg = []\n",
    "            if pd.notna(r[\"X1\"]) and r[\"X1\"] > 1_000_000:\n",
    "                msg.append(\"Unrealistic credit limit (>1,000,000).\")\n",
    "            if pd.notna(r[\"X1\"]) and r[\"X1\"] <= 0:\n",
    "                msg.append(\"Invalid credit limit (<=0).\")\n",
    "            if pd.notna(r[\"X5\"]) and r[\"X5\"] < 18:\n",
    "                msg.append(\"Invalid age (<18).\")\n",
    "            if pd.notna(r[\"X5\"]) and r[\"X5\"] > 100:\n",
    "                msg.append(\"Unrealistic age (>100).\")\n",
    "            if msg:\n",
    "                flags.append(True); reasons.append(\"; \".join(msg))\n",
    "            else:\n",
    "                flags.append(False); reasons.append(\"No issues detected.\")\n",
    "        df[\"llm_flag\"] = flags\n",
    "        df[\"llm_rationale\"] = reasons\n",
    "        self.log(\"Applied semantic rules to UCI Credit dataset.\")\n",
    "        return df\n",
    "\n",
    "    def imdb_label_check(self, df, text_col=\"review\", label_col=\"sentiment\"):\n",
    "        out = []\n",
    "        for txt in df[text_col].astype(str).fillna(\"\"):\n",
    "            out.append(self.sentiment_pipe(txt[:512])[0][\"label\"].lower())\n",
    "        df[\"llm_sentiment\"] = out\n",
    "\n",
    "        flags, rats = [], []\n",
    "        for _, r in df.iterrows():\n",
    "            gold = str(r[label_col]).lower()\n",
    "            pred = r[\"llm_sentiment\"]\n",
    "            if gold.startswith(\"pos\") and pred == \"negative\":\n",
    "                flags.append(True); rats.append(\"Mismatch: labeled POS but looks NEG.\")\n",
    "            elif gold.startswith(\"neg\") and pred == \"positive\":\n",
    "                flags.append(True); rats.append(\"Mismatch: labeled NEG but looks POS.\")\n",
    "            else:\n",
    "                flags.append(False); rats.append(\"Aligned with sentiment.\")\n",
    "        df[\"llm_flag\"] = flags\n",
    "        df[\"llm_rationale\"] = rats\n",
    "        self.log(\"Checked IMDb dataset with LLM sentiment model.\")\n",
    "        return df\n",
    "\n",
    "    # --- Evaluation Functions ---\n",
    "    def train_and_evaluate(self, df, target_col=\"Y\", dataset=\"uci\"):\n",
    "        X = df.drop(columns=[target_col])\n",
    "        y = df[target_col]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        results = {}\n",
    "\n",
    "        # RandomForest\n",
    "        rf = RandomForestClassifier(random_state=42)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred_rf = rf.predict(X_test)\n",
    "        results[\"RandomForest\"] = {\n",
    "            \"Accuracy\": accuracy_score(y_test, y_pred_rf),\n",
    "            \"F1\": f1_score(y_test, y_pred_rf, average=\"weighted\")\n",
    "        }\n",
    "\n",
    "        # XGBoost\n",
    "        xgb_model = xgb.XGBClassifier(eval_metric=\"logloss\", use_label_encoder=False)\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "        y_pred_xgb = xgb_model.predict(X_test)\n",
    "        results[\"XGBoost\"] = {\n",
    "            \"Accuracy\": accuracy_score(y_test, y_pred_xgb),\n",
    "            \"F1\": f1_score(y_test, y_pred_xgb, average=\"weighted\")\n",
    "        }\n",
    "\n",
    "        self.log(f\"Trained & evaluated models on {dataset} dataset.\")\n",
    "        return results\n",
    "\n",
    "    # --- Export ---\n",
    "    def export_logs(self, filename=\"datacrine_log.txt\"):\n",
    "        with open(filename, \"w\") as f:\n",
    "            for line in self.logs:\n",
    "                f.write(line + \"\\n\")\n",
    "        self.log(f\"Logs exported to {filename}\")\n",
    "\n",
    "    def save_dataset(self, df, filename=\"datacrine_cleaned.csv\"):\n",
    "        df.to_csv(filename, index=False)\n",
    "        self.log(f\"Cleaned dataset saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2ad184-e2f3-4021-8d7e-eec8a11ec074",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = Datacrine()\n",
    "\n",
    "# UCI Cleaning\n",
    "uci_cleaned = dc.impute_numeric_mean(uci_credit.copy(), [\"X5\"])\n",
    "uci_cleaned = dc.cap_outliers_iqr(uci_cleaned, [\"X1\"])\n",
    "uci_cleaned = dc.uci_semantic_rules(uci_cleaned)\n",
    "uci_cleaned[\"Y\"] = uci_credit[\"Y\"].values\n",
    "uci_results = dc.train_and_evaluate(uci_cleaned, target_col=\"Y\", dataset=\"uci\")\n",
    "print(\"UCI Results:\", uci_results)\n",
    "\n",
    "# IMDb Cleaning (subset for speed!)\n",
    "imdb_subset = imdb.sample(2000, random_state=42).copy()\n",
    "imdb_cleaned = dc.imdb_label_check(imdb_subset)\n",
    "imdb_cleaned[\"Y\"] = imdb_subset[\"sentiment\"].map({\"positive\": 1, \"negative\": 0})\n",
    "imdb_results = dc.train_and_evaluate(imdb_cleaned.rename(columns={\"llm_sentiment\":\"Y\"}), target_col=\"Y\", dataset=\"imdb\")\n",
    "print(\"IMDb Results:\", imdb_results)\n",
    "\n",
    "# Export logs & cleaned dataset\n",
    "dc.export_logs(\"datacrine_audit.txt\")\n",
    "dc.save_dataset(uci_cleaned, \"uci_credit_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6221bef-b8f0-42f2-ad09-6ec0d0642f76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
