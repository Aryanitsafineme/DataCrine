{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df05cd88-8b9b-42e2-b105-e704a8b8a9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Datacrine Machine — Cell 1\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Any, List, Optional\n",
    "from pathlib import Path\n",
    "import hashlib, csv, json, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- Configs ----------\n",
    "@dataclass\n",
    "class ConfigTabular:\n",
    "    target: str\n",
    "    impute_numeric: str = \"median\"          # \"median\" or \"mean\"\n",
    "    impute_categorical: str = \"most_frequent\"\n",
    "    iqr_clip: bool = True\n",
    "    iqr_group_by: Optional[List[str]] = None\n",
    "    category_alias_map: Optional[Dict[str, Dict[str,str]]] = None  # {column: {lowercase_value: canonical_value}}\n",
    "    dup_cols: Optional[List[str]] = None\n",
    "    cv_folds: int = 5\n",
    "\n",
    "@dataclass\n",
    "class ConfigNLP:\n",
    "    text_col: str\n",
    "    target: str\n",
    "    normalize_lower: bool = True\n",
    "    normalize_strip_urls: bool = True\n",
    "    dedup: bool = True\n",
    "    cv_folds: int = 5\n",
    "\n",
    "# ---------- Result ----------\n",
    "@dataclass\n",
    "class Result:\n",
    "    cleaned_df: pd.DataFrame\n",
    "    edits_df: pd.DataFrame\n",
    "    metrics_pre: Dict[str, Any]\n",
    "    metrics_post: Dict[str, Any]\n",
    "    artifacts: Dict[str, str]\n",
    "    deltas: Dict[str, Any]\n",
    "\n",
    "# ---------- small helpers ----------\n",
    "def _safe_auc(y_true, proba):\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    try:\n",
    "        return float(roc_auc_score(y_true, proba))\n",
    "    except Exception:\n",
    "        return float(\"nan\")\n",
    "\n",
    "def _safe_brier(y_true, proba):\n",
    "    from sklearn.metrics import brier_score_loss\n",
    "    try:\n",
    "        return float(brier_score_loss(y_true, proba))\n",
    "    except Exception:\n",
    "        return float(\"nan\")\n",
    "\n",
    "def _delta(a, b):\n",
    "    try:\n",
    "        return round(float(b) - float(a), 4)\n",
    "    except Exception:\n",
    "        return float(\"nan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1182366e-4a40-49c6-ba4a-cd69c28dd60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datacrine Machine — Cell 2 (Audit Log)\n",
    "class EditLog:\n",
    "    def __init__(self, path: Path):\n",
    "        self.path = Path(path)\n",
    "        self.path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        if not self.path.exists():\n",
    "            with self.path.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "                csv.writer(f).writerow([\"row_id\",\"column\",\"op\",\"before\",\"after\",\"reason\",\"confidence\"])\n",
    "        self._rows = []\n",
    "\n",
    "    @staticmethod\n",
    "    def _row_id(row: Dict[str, Any]) -> str:\n",
    "        return hashlib.md5(str(tuple(row.values())).encode(\"utf-8\")).hexdigest()[:10]\n",
    "\n",
    "    def write(self, row_dict: Dict[str,Any], column: str, op: str, before, after, reason: str, conf: float = 1.0):\n",
    "        rid = EditLog._row_id(row_dict)\n",
    "        self._rows.append([rid, column, op, str(before), str(after), reason, f\"{conf:.2f}\"])\n",
    "\n",
    "    def save(self) -> pd.DataFrame:\n",
    "        with self.path.open(\"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            w = csv.writer(f)\n",
    "            for r in self._rows:\n",
    "                w.writerow(r)\n",
    "        df = pd.DataFrame(self._rows, columns=[\"row_id\",\"column\",\"op\",\"before\",\"after\",\"reason\",\"confidence\"])\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c4ca587-8721-4473-a254-5b9ed54b94bc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Datacrine Machine — Cell 3 (Core)\n",
    "class DatacrineMachine:\n",
    "    def __init__(self, artifacts_dir: str = \"artifacts\", seed: int = 42):\n",
    "        self.seed = seed\n",
    "        np.random.seed(seed)\n",
    "        self.artifacts_dir = Path(artifacts_dir)\n",
    "        self.artifacts_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # ---------------- TABULAR ----------------\n",
    "    def run_tabular(self, csv_path: str, cfg: ConfigTabular) -> Result:\n",
    "        outdir = self.artifacts_dir / \"uci\"\n",
    "        outdir.mkdir(parents=True, exist_ok=True)\n",
    "        df_raw = pd.read_csv(csv_path)\n",
    "        df = df_raw.copy()\n",
    "        edits = EditLog(outdir / \"edits.csv\")\n",
    "\n",
    "        # Impute\n",
    "        num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        cat_cols = [c for c in df.columns if c not in num_cols]\n",
    "        if cfg.impute_numeric in (\"median\",\"mean\"):\n",
    "            for c in num_cols:\n",
    "                if df[c].isna().any():\n",
    "                    val = df[c].median() if cfg.impute_numeric==\"median\" else df[c].mean()\n",
    "                    na_idx = df[c].isna()\n",
    "                    for idx in df[na_idx].index[:1000]:\n",
    "                        edits.write(df.loc[idx].to_dict(), c, \"impute_numeric\", None, val, f\"{cfg.impute_numeric} imputation\", 0.95)\n",
    "                    df.loc[na_idx, c] = val\n",
    "        if cfg.impute_categorical == \"most_frequent\":\n",
    "            for c in cat_cols:\n",
    "                if df[c].isna().any():\n",
    "                    mode_val = df[c].mode(dropna=True).iloc[0] if df[c].notna().any() else \"\"\n",
    "                    na_idx = df[c].isna()\n",
    "                    for idx in df[na_idx].index[:1000]:\n",
    "                        edits.write(df.loc[idx].to_dict(), c, \"impute_categorical\", None, mode_val, \"mode imputation\", 0.95)\n",
    "                    df.loc[na_idx, c] = mode_val\n",
    "\n",
    "        # IQR clip\n",
    "        if cfg.iqr_clip:\n",
    "            if cfg.iqr_group_by:\n",
    "                for key, part in df.groupby(cfg.iqr_group_by):\n",
    "                    for col in num_cols:\n",
    "                        q1 = part[col].quantile(0.25); q3 = part[col].quantile(0.75); iqr = q3-q1\n",
    "                        if pd.isna(iqr) or iqr==0: continue\n",
    "                        lo, hi = q1-1.5*iqr, q3+1.5*iqr\n",
    "                        mask = (part[col]<lo) | (part[col]>hi)\n",
    "                        for idx in part[mask].index[:1000]:\n",
    "                            before = df.at[idx, col]\n",
    "                            after = float(np.clip(before, lo, hi))\n",
    "                            edits.write(df.loc[idx].to_dict(), col, \"iqr_clip\", before, after, \"IQR clip (grouped)\", 0.90)\n",
    "                        df.loc[part.index, col] = df.loc[part.index, col].clip(lo, hi)\n",
    "            else:\n",
    "                for col in num_cols:\n",
    "                    q1 = df[col].quantile(0.25); q3 = df[col].quantile(0.75); iqr = q3-q1\n",
    "                    if pd.isna(iqr) or iqr==0: continue\n",
    "                    lo, hi = q1-1.5*iqr, q3+1.5*iqr\n",
    "                    mask = (df[col]<lo) | (df[col]>hi)\n",
    "                    for idx in df[mask].index[:1000]:\n",
    "                        before = df.at[idx, col]\n",
    "                        after = float(np.clip(before, lo, hi))\n",
    "                        edits.write(df.loc[idx].to_dict(), col, \"iqr_clip\", before, after, \"IQR clip\", 0.90)\n",
    "                    df[col] = df[col].clip(lo, hi)\n",
    "\n",
    "        # Category aliasing\n",
    "        if cfg.category_alias_map:\n",
    "            for col, mapping in cfg.category_alias_map.items():\n",
    "                if col not in df.columns: continue\n",
    "                before = df[col].copy()\n",
    "                def _map(v):\n",
    "                    if pd.isna(v): return v\n",
    "                    key = str(v).strip().lower()\n",
    "                    return mapping.get(key, v)\n",
    "                df[col] = df[col].map(_map)\n",
    "                changed = before != df[col]\n",
    "                for idx in df[changed].index[:1000]:\n",
    "                    edits.write(df.loc[idx].to_dict(), col, \"category_alias\", before.at[idx], df.at[idx, col], \"alias map\", 0.98)\n",
    "\n",
    "        # Near-duplicate drop\n",
    "        dup_cols = cfg.dup_cols if cfg.dup_cols else [c for c in df.columns if df[c].dtype==object]\n",
    "        if dup_cols:\n",
    "            seen = set(); keep = []\n",
    "            for i, row in df.iterrows():\n",
    "                key = \"|\".join(str(row[c]).strip().lower() for c in dup_cols)\n",
    "                h = hashlib.sha1(key.encode(\"utf-8\")).hexdigest()[:16]\n",
    "                if h in seen:\n",
    "                    edits.write(row.to_dict(), \"*\", \"near_dup_drop\", key, \"—\", \"hash drop\", 0.90)\n",
    "                    continue\n",
    "                seen.add(h); keep.append(i)\n",
    "            df = df.loc[keep].reset_index(drop=True)\n",
    "\n",
    "        # Evaluate pre/post\n",
    "        pre = self._eval_tabular(df_raw, cfg.target, cfg.cv_folds)\n",
    "        post = self._eval_tabular(df, cfg.target, cfg.cv_folds)\n",
    "\n",
    "        # Save artifacts\n",
    "        cleaned_p = outdir / \"cleaned.csv\"; df.to_csv(cleaned_p, index=False)\n",
    "        edits_df = edits.save()\n",
    "        pre_p = outdir / \"metrics_pre.json\"; post_p = outdir / \"metrics_post.json\"\n",
    "        json.dump(pre, open(pre_p,\"w\")); json.dump(post, open(post_p,\"w\"))\n",
    "        report_p = outdir / \"report.html\"\n",
    "        self._write_report(report_p, \"uci\", pre, post, {\n",
    "            \"delta_auc\": _delta(pre.get(\"auc\"), post.get(\"auc\")),\n",
    "            \"delta_f1\": _delta(pre.get(\"f1\"), post.get(\"f1\"))\n",
    "        })\n",
    "        artifacts = {\"cleaned\": str(cleaned_p), \"edits\": str(edits.path), \"metrics_pre\": str(pre_p), \"metrics_post\": str(post_p), \"report\": str(report_p)}\n",
    "        return Result(df, edits_df, pre, post, artifacts, {\"delta_auc\": _delta(pre.get(\"auc\"), post.get(\"auc\")), \"delta_f1\": _delta(pre.get(\"f1\"), post.get(\"f1\"))})\n",
    "\n",
    "    # ---------------- NLP ----------------\n",
    "    def run_nlp(self, csv_path: str, cfg: ConfigNLP) -> Result:\n",
    "        outdir = self.artifacts_dir / \"imdb\"\n",
    "        outdir.mkdir(parents=True, exist_ok=True)\n",
    "        df_raw = pd.read_csv(csv_path)\n",
    "        df = df_raw.copy()\n",
    "        edits = EditLog(outdir / \"edits.csv\")\n",
    "\n",
    "        # Normalize\n",
    "        url_re = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
    "        ser = df[cfg.text_col].astype(str).copy()\n",
    "        if cfg.normalize_strip_urls or cfg.normalize_lower:\n",
    "            for i, t in ser.items():\n",
    "                orig = t\n",
    "                if cfg.normalize_strip_urls: t = url_re.sub(\"\", t)\n",
    "                if cfg.normalize_lower: t = t.lower()\n",
    "                if t != orig and len(edits._rows) < 1000:\n",
    "                    edits.write({\"text\": orig}, cfg.text_col, \"normalize\", orig[:80], t[:80], \"urls/lower\", 0.95)\n",
    "                ser.at[i] = t\n",
    "        df[cfg.text_col] = ser\n",
    "\n",
    "        # Dedup\n",
    "        if cfg.dedup:\n",
    "            seen = set(); keep = []\n",
    "            for i, t in df[cfg.text_col].astype(str).items():\n",
    "                key = hashlib.sha1(t.strip().lower().encode(\"utf-8\")).hexdigest()[:16]\n",
    "                if key in seen:\n",
    "                    edits.write({\"text\": t}, cfg.text_col, \"near_dup_drop\", \"hash\", \"—\", \"exact/near dup\", 0.90)\n",
    "                    continue\n",
    "                seen.add(key); keep.append(i)\n",
    "            df = df.loc[keep].reset_index(drop=True)\n",
    "\n",
    "        # Evaluate pre/post\n",
    "        pre = self._eval_nlp(df_raw, cfg.text_col, cfg.target, cfg.cv_folds)\n",
    "        post = self._eval_nlp(df, cfg.text_col, cfg.target, cfg.cv_folds)\n",
    "\n",
    "        # Save artifacts\n",
    "        cleaned_p = outdir / \"cleaned.csv\"; df.to_csv(cleaned_p, index=False)\n",
    "        edits_df = edits.save()\n",
    "        pre_p = outdir / \"metrics_pre.json\"; post_p = outdir / \"metrics_post.json\"\n",
    "        json.dump(pre, open(pre_p,\"w\")); json.dump(post, open(post_p,\"w\"))\n",
    "        report_p = outdir / \"report.html\"\n",
    "        self._write_report(report_p, \"imdb\", pre, post, {\n",
    "            \"delta_accuracy\": _delta(pre.get(\"accuracy\"), post.get(\"accuracy\")),\n",
    "            \"delta_f1\": _delta(pre.get(\"f1\"), post.get(\"f1\"))\n",
    "        })\n",
    "        artifacts = {\"cleaned\": str(cleaned_p), \"edits\": str(edits.path), \"metrics_pre\": str(pre_p), \"metrics_post\": str(post_p), \"report\": str(report_p)}\n",
    "        return Result(df, edits_df, pre, post, artifacts, {\"delta_accuracy\": _delta(pre.get(\"accuracy\"), post.get(\"accuracy\")), \"delta_f1\": _delta(pre.get(\"f1\"), post.get(\"f1\"))})\n",
    "\n",
    "    # ---------------- Private: evaluation ----------------\n",
    "    def _eval_tabular(self, df: pd.DataFrame, target: str, folds: int) -> Dict[str, Any]:\n",
    "        from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "        from sklearn.metrics import roc_auc_score, f1_score, brier_score_loss\n",
    "        from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "        from sklearn.compose import ColumnTransformer\n",
    "        from sklearn.pipeline import Pipeline\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        from sklearn.impute import SimpleImputer\n",
    "\n",
    "        y = df[target].values\n",
    "        X = df.drop(columns=[target])\n",
    "        num = X.select_dtypes(include=\"number\").columns.tolist()\n",
    "        cat = [c for c in X.columns if c not in num]\n",
    "\n",
    "        pre = ColumnTransformer([\n",
    "            (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\")), (\"sc\", StandardScaler(with_mean=False))]), num),\n",
    "            (\"cat\", Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")), (\"oh\", OneHotEncoder(handle_unknown=\"ignore\"))]), cat)\n",
    "        ])\n",
    "        clf = RandomForestClassifier(n_estimators=200, random_state=self.seed, n_jobs=-1)\n",
    "\n",
    "        class_counts = pd.Series(y).value_counts()\n",
    "        if len(class_counts)==1 or int(class_counts.min()) < 2:\n",
    "            Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, stratify=y if len(class_counts)>1 else None, random_state=self.seed)\n",
    "            pipe = Pipeline([(\"pre\", pre), (\"clf\", clf)]).fit(Xtr, ytr)\n",
    "            proba = pipe.predict_proba(Xte)[:,1]; pred = (proba>=0.5).astype(int)\n",
    "            auc = _safe_auc(yte, proba); brier = _safe_brier(yte, proba)\n",
    "            return {\"auc\": auc, \"f1\": float(f1_score(yte, pred)), \"brier\": brier}\n",
    "\n",
    "        n_folds = min(folds, max(2, int(class_counts.min())))\n",
    "        skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=self.seed)\n",
    "        aucs=[]; f1s=[]; briers=[]\n",
    "        for tr, te in skf.split(X, y):\n",
    "            Xtr, Xte = X.iloc[tr], X.iloc[te]; ytr, yte = y[tr], y[te]\n",
    "            pipe = Pipeline([(\"pre\", pre), (\"clf\", clf)]).fit(Xtr, ytr)\n",
    "            proba = pipe.predict_proba(Xte)[:,1]; pred = (proba>=0.5).astype(int)\n",
    "            aucs.append(_safe_auc(yte, proba)); f1s.append(float(f1_score(yte, pred))); briers.append(_safe_brier(yte, proba))\n",
    "        return {\"auc\": float(np.nanmean(aucs)), \"f1\": float(np.nanmean(f1s)), \"brier\": float(np.nanmean(briers))}\n",
    "\n",
    "    def _eval_nlp(self, df: pd.DataFrame, text_col: str, target: str, folds: int) -> Dict[str, Any]:\n",
    "        from sklearn.model_selection import StratifiedKFold\n",
    "        from sklearn.metrics import f1_score, accuracy_score\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "        y = df[target].values\n",
    "        texts = df[text_col].astype(str).tolist()\n",
    "\n",
    "        class_counts = pd.Series(y).value_counts()\n",
    "        if len(class_counts)==1 or int(class_counts.min()) < 2:\n",
    "            # simple holdout w/o stratify if only one class\n",
    "            tr_idx = int(len(texts)*0.8)\n",
    "            vec = TfidfVectorizer(max_features=20000)\n",
    "            X = vec.fit_transform(texts)\n",
    "            Xtr, Xte = X[:tr_idx], X[tr_idx:]\n",
    "            ytr, yte = y[:tr_idx], y[tr_idx:]\n",
    "            clf = LogisticRegression(max_iter=300).fit(Xtr, ytr)\n",
    "            pred = clf.predict(Xte)\n",
    "            return {\"accuracy\": float(accuracy_score(y[tr_idx:], pred)), \"f1\": float(f1_score(y[tr_idx:], pred))}\n",
    "        n_folds = min(folds, max(2, int(class_counts.min())))\n",
    "        skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=self.seed)\n",
    "        accs=[]; f1s=[]\n",
    "        for tr, te in skf.split(texts, y):\n",
    "            vec = TfidfVectorizer(max_features=20000)\n",
    "            Xtr = vec.fit_transform([texts[i] for i in tr])\n",
    "            Xte = vec.transform([texts[i] for i in te])\n",
    "            clf = LogisticRegression(max_iter=300).fit(Xtr, y[tr])\n",
    "            pred = clf.predict(Xte)\n",
    "            accs.append(float(accuracy_score(y[te], pred))); f1s.append(float(f1_score(y[te], pred)))\n",
    "        return {\"accuracy\": float(np.mean(accs)), \"f1\": float(np.mean(f1s))}\n",
    "\n",
    "    # ---------------- Private: HTML report ----------------\n",
    "    def _write_report(self, path: Path, track: str, pre: Dict[str,Any], post: Dict[str,Any], extra: Dict[str,Any]):\n",
    "        html = f\"\"\"<!doctype html><html><head><meta charset='utf-8'><title>Datacrine Report – {track}</title>\n",
    "        <style>body{{font-family:system-ui;margin:2rem}} .k{{font-weight:600}} table{{border-collapse:collapse}} td,th{{border:1px solid #ddd;padding:6px}}</style>\n",
    "        </head><body>\n",
    "        <h1>Datacrine Report – {track}</h1>\n",
    "        <p><span class='k'>Pre metrics:</span> {json.dumps(pre)}</p>\n",
    "        <p><span class='k'>Post metrics:</span> {json.dumps(post)}</p>\n",
    "        <p><span class='k'>Deltas:</span> {json.dumps(extra)}</p>\n",
    "        </body></html>\"\"\"\n",
    "        Path(path).write_text(html, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1abe076-0674-4e05-9410-f6d75c4d5c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic CSVs written to ./data/\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL smoke test data\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "Path(\"data\").mkdir(exist_ok=True)\n",
    "\n",
    "# Tabular-ish dataset\n",
    "np.random.seed(42); N=500\n",
    "uci = pd.DataFrame({\n",
    "    \"LIMIT_BAL\": np.random.normal(200000, 50000, N),\n",
    "    \"SEX\": np.random.choice([1,2], N),\n",
    "    \"EDUCATION\": np.random.choice([\"high school\",\"High School\",\"university\",\"grad\"], N),\n",
    "    \"AGE\": np.random.randint(20, 70, N),\n",
    "    \"PAY_AMT1\": np.abs(np.random.normal(2000, 1200, N)),\n",
    "    \"PAY_AMT2\": np.abs(np.random.normal(1800, 1100, N)),\n",
    "    \"default_payment_next_month\": np.random.choice([0,1], N, p=[0.7,0.3]),\n",
    "})\n",
    "uci.loc[np.random.choice(N, 15, replace=False), \"PAY_AMT1\"] = np.nan\n",
    "uci.loc[np.random.choice(N, 5, replace=False), \"LIMIT_BAL\"] *= 5\n",
    "uci.to_csv(\"data/uci_credit.csv\", index=False)\n",
    "\n",
    "# NLP-ish dataset\n",
    "texts = [\n",
    "    \"I loved this movie! Fantastic acting and story.\",\n",
    "    \"Terrible film... waste of time http://spam.example\",\n",
    "    \"It was okay, not great, not bad.\",\n",
    "    \"Absolutely brilliant! Would watch again.\",\n",
    "    \"Worst movie ever. I hated it so much.\",\n",
    "    \"Loved it loved it loved it!\",\n",
    "    \"Meh, I've seen better.\",\n",
    "    \"Great cinematography, weak plot though.\",\n",
    "    \"Terrific performances!\",\n",
    "    \"awful experience!!!\"\n",
    "]\n",
    "labels = [1,0,1,1,0,1,0,1,1,0]\n",
    "imdb = pd.DataFrame({\"text\": texts*50, \"label\": labels*50})\n",
    "imdb.to_csv(\"data/imdb.csv\", index=False)\n",
    "\n",
    "print(\"Synthetic CSVs written to ./data/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "973eae9e-6d3b-4a8c-ab2e-a3c49ff09fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts (tabular):\n",
      "default_payment_next_month\n",
      "0    340\n",
      "1    160\n",
      "Name: count, dtype: int64\n",
      "TABULAR deltas: {'delta_auc': nan, 'delta_f1': -0.2015}\n",
      "TABULAR artifacts: {'cleaned': 'artifacts\\\\uci\\\\cleaned.csv', 'edits': 'artifacts\\\\uci\\\\edits.csv', 'metrics_pre': 'artifacts\\\\uci\\\\metrics_pre.json', 'metrics_post': 'artifacts\\\\uci\\\\metrics_post.json', 'report': 'artifacts\\\\uci\\\\report.html'}\n",
      "NLP deltas: {'delta_accuracy': -0.4167, 'delta_f1': -0.2667}\n",
      "NLP artifacts: {'cleaned': 'artifacts\\\\imdb\\\\cleaned.csv', 'edits': 'artifacts\\\\imdb\\\\edits.csv', 'metrics_pre': 'artifacts\\\\imdb\\\\metrics_pre.json', 'metrics_post': 'artifacts\\\\imdb\\\\metrics_post.json', 'report': 'artifacts\\\\imdb\\\\report.html'}\n"
     ]
    }
   ],
   "source": [
    "# === Cell 5 (SAFE RUN) ===\n",
    "# Patches _eval_tabular at runtime to avoid stratify errors on tiny classes,\n",
    "# then runs both Tabular and NLP pipelines.\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score, brier_score_loss, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# --- runtime patch: robust _eval_tabular (no stratify if any class < 2) ---\n",
    "def _patched_eval_tabular(self, df: pd.DataFrame, target: str, folds: int):\n",
    "    y = df[target].values\n",
    "    X = df.drop(columns=[target])\n",
    "    num = X.select_dtypes(include=\"number\").columns.tolist()\n",
    "    cat = [c for c in X.columns if c not in num]\n",
    "\n",
    "    pre = ColumnTransformer([\n",
    "        (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "                          (\"sc\", StandardScaler(with_mean=False))]), num),\n",
    "        (\"cat\", Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                          (\"oh\", OneHotEncoder(handle_unknown=\"ignore\"))]), cat)\n",
    "    ])\n",
    "    clf = RandomForestClassifier(n_estimators=200, random_state=self.seed, n_jobs=-1)\n",
    "\n",
    "    class_counts = pd.Series(y).value_counts()\n",
    "    min_class = int(class_counts.min()) if len(class_counts) > 0 else 0\n",
    "\n",
    "    if len(class_counts) <= 1 or min_class < 2:\n",
    "        stratify_arg = y if (len(class_counts) > 1 and min_class >= 2) else None\n",
    "        Xtr, Xte, ytr, yte = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=self.seed, stratify=stratify_arg\n",
    "        )\n",
    "        pipe = Pipeline([(\"pre\", pre), (\"clf\", clf)]).fit(Xtr, ytr)\n",
    "        proba = pipe.predict_proba(Xte)[:, 1]\n",
    "        pred = (proba >= 0.5).astype(int)\n",
    "        try:\n",
    "            auc = float(roc_auc_score(yte, proba))\n",
    "            brier = float(brier_score_loss(yte, proba))\n",
    "        except Exception:\n",
    "            auc = float(\"nan\"); brier = float(\"nan\")\n",
    "        return {\"auc\": auc, \"f1\": float(f1_score(yte, pred)), \"brier\": brier}\n",
    "\n",
    "    n_folds = min(folds, max(2, min_class))\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=self.seed)\n",
    "    aucs, f1s, briers = [], [], []\n",
    "    for tr, te in skf.split(X, y):\n",
    "        Xtr, Xte = X.iloc[tr], X.iloc[te]; ytr, yte = y[tr], y[te]\n",
    "        pipe = Pipeline([(\"pre\", pre), (\"clf\", clf)]).fit(Xtr, ytr)\n",
    "        proba = pipe.predict_proba(Xte)[:, 1]\n",
    "        pred = (proba >= 0.5).astype(int)\n",
    "        try:\n",
    "            aucs.append(float(roc_auc_score(yte, proba)))\n",
    "            briers.append(float(brier_score_loss(yte, proba)))\n",
    "        except Exception:\n",
    "            aucs.append(float(\"nan\")); briers.append(float(\"nan\"))\n",
    "        f1s.append(float(f1_score(yte, pred)))\n",
    "    return {\"auc\": float(np.nanmean(aucs)), \"f1\": float(np.nanmean(f1s)), \"brier\": float(np.nanmean(briers))}\n",
    "\n",
    "# apply patch\n",
    "DatacrineMachine._eval_tabular = _patched_eval_tabular\n",
    "\n",
    "# ---- Run the machine ----\n",
    "m = DatacrineMachine(artifacts_dir=\"artifacts\")\n",
    "\n",
    "# (Optional) See class balance before running\n",
    "try:\n",
    "    tmp_df = pd.read_csv(\"data/uci_credit.csv\")\n",
    "    print(\"Class counts (tabular):\")\n",
    "    print(tmp_df[\"default_payment_next_month\"].value_counts(dropna=False))\n",
    "except Exception as e:\n",
    "    print(\"Could not preview class counts:\", e)\n",
    "\n",
    "# Tabular\n",
    "tab_cfg = ConfigTabular(\n",
    "    target=\"default_payment_next_month\",\n",
    "    impute_numeric=\"median\",\n",
    "    impute_categorical=\"most_frequent\",\n",
    "    iqr_clip=True,\n",
    "    iqr_group_by=None,\n",
    "    category_alias_map=None,\n",
    "    dup_cols=None,\n",
    "    cv_folds=5\n",
    ")\n",
    "tab_res = m.run_tabular(\"data/uci_credit.csv\", tab_cfg)\n",
    "print(\"TABULAR deltas:\", tab_res.deltas)\n",
    "print(\"TABULAR artifacts:\", tab_res.artifacts)\n",
    "\n",
    "# NLP\n",
    "nlp_cfg = ConfigNLP(\n",
    "    text_col=\"text\",\n",
    "    target=\"label\",\n",
    "    normalize_lower=True,\n",
    "    normalize_strip_urls=True,\n",
    "    dedup=True,\n",
    "    cv_folds=5\n",
    ")\n",
    "nlp_res = m.run_nlp(\"data/imdb.csv\", nlp_cfg)\n",
    "print(\"NLP deltas:\", nlp_res.deltas)\n",
    "print(\"NLP artifacts:\", nlp_res.artifacts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba9ac6e8-4aa1-4021-b477-ed70aea51e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/aryan/Downloads/datacrine_machine.py')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save everything above into a single importable file\n",
    "module_path = Path(\"datacrine_machine.py\")\n",
    "module_src = r'''\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Any, List, Optional\n",
    "from pathlib import Path\n",
    "import hashlib, csv, json, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "@dataclass\n",
    "class ConfigTabular:\n",
    "    target: str\n",
    "    impute_numeric: str = \"median\"\n",
    "    impute_categorical: str = \"most_frequent\"\n",
    "    iqr_clip: bool = True\n",
    "    iqr_group_by: Optional[List[str]] = None\n",
    "    category_alias_map: Optional[Dict[str, Dict[str,str]]] = None\n",
    "    dup_cols: Optional[List[str]] = None\n",
    "    cv_folds: int = 5\n",
    "\n",
    "@dataclass\n",
    "class ConfigNLP:\n",
    "    text_col: str\n",
    "    target: str\n",
    "    normalize_lower: bool = True\n",
    "    normalize_strip_urls: bool = True\n",
    "    dedup: bool = True\n",
    "    cv_folds: int = 5\n",
    "\n",
    "@dataclass\n",
    "class Result:\n",
    "    cleaned_df: pd.DataFrame\n",
    "    edits_df: pd.DataFrame\n",
    "    metrics_pre: Dict[str, Any]\n",
    "    metrics_post: Dict[str, Any]\n",
    "    artifacts: Dict[str, str]\n",
    "    deltas: Dict[str, Any]\n",
    "\n",
    "def _safe_auc(y_true, proba):\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    try:\n",
    "        return float(roc_auc_score(y_true, proba))\n",
    "    except Exception:\n",
    "        return float(\"nan\")\n",
    "\n",
    "def _safe_brier(y_true, proba):\n",
    "    from sklearn.metrics import brier_score_loss\n",
    "    try:\n",
    "        return float(brier_score_loss(y_true, proba))\n",
    "    except Exception:\n",
    "        return float(\"nan\")\n",
    "\n",
    "def _delta(a, b):\n",
    "    try:\n",
    "        return round(float(b) - float(a), 4)\n",
    "    except Exception:\n",
    "        return float(\"nan\")\n",
    "\n",
    "class EditLog:\n",
    "    def __init__(self, path: Path):\n",
    "        self.path = Path(path)\n",
    "        self.path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        if not self.path.exists():\n",
    "            with self.path.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "                csv.writer(f).writerow([\"row_id\",\"column\",\"op\",\"before\",\"after\",\"reason\",\"confidence\"])\n",
    "        self._rows = []\n",
    "    @staticmethod\n",
    "    def _row_id(row: Dict[str, Any]) -> str:\n",
    "        return hashlib.md5(str(tuple(row.values())).encode(\"utf-8\")).hexdigest()[:10]\n",
    "    def write(self, row_dict: Dict[str,Any], column: str, op: str, before, after, reason: str, conf: float = 1.0):\n",
    "        rid = EditLog._row_id(row_dict)\n",
    "        self._rows.append([rid, column, op, str(before), str(after), reason, f\"{conf:.2f}\"])\n",
    "    def save(self) -> pd.DataFrame:\n",
    "        with self.path.open(\"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            csv.writer(f).writerow  # ensure import of csv writer\n",
    "        with self.path.open(\"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            w = csv.writer(f)\n",
    "            for r in self._rows:\n",
    "                w.writerow(r)\n",
    "        return pd.DataFrame(self._rows, columns=[\"row_id\",\"column\",\"op\",\"before\",\"after\",\"reason\",\"confidence\"])\n",
    "\n",
    "class DatacrineMachine:\n",
    "    def __init__(self, artifacts_dir: str = \"artifacts\", seed: int = 42):\n",
    "        self.seed = seed\n",
    "        np.random.seed(seed)\n",
    "        self.artifacts_dir = Path(artifacts_dir)\n",
    "        self.artifacts_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def run_tabular(self, csv_path: str, cfg: ConfigTabular) -> Result:\n",
    "        outdir = self.artifacts_dir / \"uci\"\n",
    "        outdir.mkdir(parents=True, exist_ok=True)\n",
    "        df_raw = pd.read_csv(csv_path)\n",
    "        df = df_raw.copy()\n",
    "        edits = EditLog(outdir / \"edits.csv\")\n",
    "        num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        cat_cols = [c for c in df.columns if c not in num_cols]\n",
    "        if cfg.impute_numeric in (\"median\",\"mean\"):\n",
    "            for c in num_cols:\n",
    "                if df[c].isna().any():\n",
    "                    val = df[c].median() if cfg.impute_numeric==\"median\" else df[c].mean()\n",
    "                    na_idx = df[c].isna()\n",
    "                    for idx in df[na_idx].index[:1000]:\n",
    "                        edits.write(df.loc[idx].to_dict(), c, \"impute_numeric\", None, val, f\"{cfg.impute_numeric} imputation\", 0.95)\n",
    "                    df.loc[na_idx, c] = val\n",
    "        if cfg.impute_categorical == \"most_frequent\":\n",
    "            for c in cat_cols:\n",
    "                if df[c].isna().any():\n",
    "                    mode_val = df[c].mode(dropna=True).iloc[0] if df[c].notna().any() else \"\"\n",
    "                    na_idx = df[c].isna()\n",
    "                    for idx in df[na_idx].index[:1000]:\n",
    "                        edits.write(df.loc[idx].to_dict(), c, \"impute_categorical\", None, mode_val, \"mode imputation\", 0.95)\n",
    "                    df.loc[na_idx, c] = mode_val\n",
    "        if cfg.iqr_clip:\n",
    "            if cfg.iqr_group_by:\n",
    "                for key, part in df.groupby(cfg.iqr_group_by):\n",
    "                    for col in num_cols:\n",
    "                        q1 = part[col].quantile(0.25); q3 = part[col].quantile(0.75); iqr = q3-q1\n",
    "                        if pd.isna(iqr) or iqr==0: continue\n",
    "                        lo, hi = q1-1.5*iqr, q3+1.5*iqr\n",
    "                        mask = (part[col]<lo) | (part[col]>hi)\n",
    "                        for idx in part[mask].index[:1000]:\n",
    "                            before = df.at[idx, col]\n",
    "                            after = float(np.clip(before, lo, hi))\n",
    "                            edits.write(df.loc[idx].to_dict(), col, \"iqr_clip\", before, after, \"IQR clip (grouped)\", 0.90)\n",
    "                        df.loc[part.index, col] = df.loc[part.index, col].clip(lo, hi)\n",
    "            else:\n",
    "                for col in num_cols:\n",
    "                    q1 = df[col].quantile(0.25); q3 = df[col].quantile(0.75); iqr = q3-q1\n",
    "                    if pd.isna(iqr) or iqr==0: continue\n",
    "                    lo, hi = q1-1.5*iqr, q3+1.5*iqr\n",
    "                    mask = (df[col]<lo) | (df[col]>hi)\n",
    "                    for idx in df[mask].index[:1000]:\n",
    "                        before = df.at[idx, col]\n",
    "                        after = float(np.clip(before, lo, hi))\n",
    "                        edits.write(df.loc[idx].to_dict(), col, \"iqr_clip\", before, after, \"IQR clip\", 0.90)\n",
    "                    df[col] = df[col].clip(lo, hi)\n",
    "        if cfg.category_alias_map:\n",
    "            for col, mapping in cfg.category_alias_map.items():\n",
    "                if col not in df.columns: continue\n",
    "                before = df[col].copy()\n",
    "                def _map(v):\n",
    "                    if pd.isna(v): return v\n",
    "                    key = str(v).strip().lower()\n",
    "                    return mapping.get(key, v)\n",
    "                df[col] = df[col].map(_map)\n",
    "                changed = before != df[col]\n",
    "                for idx in df[changed].index[:1000]:\n",
    "                    edits.write(df.loc[idx].to_dict(), col, \"category_alias\", before.at[idx], df.at[idx, col], \"alias map\", 0.98)\n",
    "        dup_cols = cfg.dup_cols if cfg.dup_cols else [c for c in df.columns if df[c].dtype==object]\n",
    "        if dup_cols:\n",
    "            seen = set(); keep = []\n",
    "            for i, row in df.iterrows():\n",
    "                key = \"|\".join(str(row[c]).strip().lower() for c in dup_cols)\n",
    "                h = hashlib.sha1(key.encode(\"utf-8\")).hexdigest()[:16]\n",
    "                if h in seen:\n",
    "                    edits.write(row.to_dict(), \"*\", \"near_dup_drop\", key, \"—\", \"hash drop\", 0.90); continue\n",
    "                seen.add(h); keep.append(i)\n",
    "            df = df.loc[keep].reset_index(drop=True)\n",
    "        pre = self._eval_tabular(df_raw, cfg.target, cfg.cv_folds)\n",
    "        post = self._eval_tabular(df, cfg.target, cfg.cv_folds)\n",
    "        outdir = self.artifacts_dir / \"uci\"\n",
    "        cleaned_p = outdir / \"cleaned.csv\"; df.to_csv(cleaned_p, index=False)\n",
    "        edits_df = edits.save()\n",
    "        pre_p = outdir / \"metrics_pre.json\"; post_p = outdir / \"metrics_post.json\"\n",
    "        json.dump(pre, open(pre_p,\"w\")); json.dump(post, open(post_p,\"w\"))\n",
    "        report_p = outdir / \"report.html\"\n",
    "        self._write_report(report_p, \"uci\", pre, post, {\"delta_auc\": _delta(pre.get(\"auc\"), post.get(\"auc\")), \"delta_f1\": _delta(pre.get(\"f1\"), post.get(\"f1\"))})\n",
    "        artifacts = {\"cleaned\": str(cleaned_p), \"edits\": str(edits.path), \"metrics_pre\": str(pre_p), \"metrics_post\": str(post_p), \"report\": str(report_p)}\n",
    "        return Result(df, edits_df, pre, post, artifacts, {\"delta_auc\": _delta(pre.get(\"auc\"), post.get(\"auc\")), \"delta_f1\": _delta(pre.get(\"f1\"), post.get(\"f1\"))})\n",
    "\n",
    "    def run_nlp(self, csv_path: str, cfg: ConfigNLP) -> Result:\n",
    "        outdir = self.artifacts_dir / \"imdb\"\n",
    "        outdir.mkdir(parents=True, exist_ok=True)\n",
    "        df_raw = pd.read_csv(csv_path)\n",
    "        df = df_raw.copy()\n",
    "        edits = EditLog(outdir / \"edits.csv\")\n",
    "        url_re = re.compile(r\"https?://\\\\S+|www\\\\.\\\\S+\")\n",
    "        ser = df[cfg.text_col].astype(str).copy()\n",
    "        if cfg.normalize_strip_urls or cfg.normalize_lower:\n",
    "            for i, t in ser.items():\n",
    "                orig = t\n",
    "                if cfg.normalize_strip_urls: t = url_re.sub(\"\", t)\n",
    "                if cfg.normalize_lower: t = t.lower()\n",
    "                if t != orig and len(edits._rows) < 1000:\n",
    "                    edits.write({\"text\": orig}, cfg.text_col, \"normalize\", orig[:80], t[:80], \"urls/lower\", 0.95)\n",
    "                ser.at[i] = t\n",
    "        df[cfg.text_col] = ser\n",
    "        if cfg.dedup:\n",
    "            seen = set(); keep = []\n",
    "            for i, t in df[cfg.text_col].astype(str).items():\n",
    "                key = hashlib.sha1(t.strip().lower().encode(\"utf-8\")).hexdigest()[:16]\n",
    "                if key in seen:\n",
    "                    edits.write({\"text\": t}, cfg.text_col, \"near_dup_drop\", \"hash\", \"—\", \"exact/near dup\", 0.90); continue\n",
    "                seen.add(key); keep.append(i)\n",
    "            df = df.loc[keep].reset_index(drop=True)\n",
    "        pre = self._eval_nlp(df_raw, cfg.text_col, cfg.target, cfg.cv_folds)\n",
    "        post = self._eval_nlp(df, cfg.text_col, cfg.target, cfg.cv_folds)\n",
    "        cleaned_p = outdir / \"cleaned.csv\"; df.to_csv(cleaned_p, index=False)\n",
    "        edits_df = edits.save()\n",
    "        pre_p = outdir / \"metrics_pre.json\"; post_p = outdir / \"metrics_post.json\"\n",
    "        json.dump(pre, open(pre_p,\"w\")); json.dump(post, open(post_p,\"w\"))\n",
    "        report_p = outdir / \"report.html\"\n",
    "        self._write_report(report_p, \"imdb\", pre, post, {\"delta_accuracy\": _delta(pre.get(\"accuracy\"), post.get(\"accuracy\")), \"delta_f1\": _delta(pre.get(\"f1\"), post.get(\"f1\"))})\n",
    "        artifacts = {\"cleaned\": str(cleaned_p), \"edits\": str(edits.path), \"metrics_pre\": str(pre_p), \"metrics_post\": str(post_p), \"report\": str(report_p)}\n",
    "        return Result(df, edits_df, pre, post, artifacts, {\"delta_accuracy\": _delta(pre.get(\"accuracy\"), post.get(\"accuracy\")), \"delta_f1\": _delta(pre.get(\"f1\"), post.get(\"f1\"))})\n",
    "\n",
    "    def _eval_tabular(self, df: pd.DataFrame, target: str, folds: int) -> Dict[str, Any]:\n",
    "        from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "        from sklearn.metrics import roc_auc_score, f1_score, brier_score_loss\n",
    "        from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "        from sklearn.compose import ColumnTransformer\n",
    "        from sklearn.pipeline import Pipeline\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        from sklearn.impute import SimpleImputer\n",
    "        y = df[target].values\n",
    "        X = df.drop(columns=[target])\n",
    "        num = X.select_dtypes(include=\"number\").columns.tolist()\n",
    "        cat = [c for c in X.columns if c not in num]\n",
    "        pre = ColumnTransformer([\n",
    "            (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\")), (\"sc\", StandardScaler(with_mean=False))]), num),\n",
    "            (\"cat\", Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")), (\"oh\", OneHotEncoder(handle_unknown=\"ignore\"))]), cat)\n",
    "        ])\n",
    "        clf = RandomForestClassifier(n_estimators=200, random_state=self.seed, n_jobs=-1)\n",
    "        class_counts = pd.Series(y).value_counts()\n",
    "        if len(class_counts)==1 or int(class_counts.min()) < 2:\n",
    "            Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, stratify=y if len(class_counts)>1 else None, random_state=self.seed)\n",
    "            pipe = Pipeline([(\"pre\", pre), (\"clf\", clf)]).fit(Xtr, ytr)\n",
    "            proba = pipe.predict_proba(Xte)[:,1]; pred = (proba>=0.5).astype(int)\n",
    "            auc = _safe_auc(yte, proba); brier = _safe_brier(yte, proba)\n",
    "            return {\"auc\": auc, \"f1\": float(f1_score(yte, pred)), \"brier\": brier}\n",
    "        n_folds = min(folds, max(2, int(class_counts.min())))\n",
    "        skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=self.seed)\n",
    "        aucs=[]; f1s=[]; briers=[]\n",
    "        for tr, te in skf.split(X, y):\n",
    "            Xtr, Xte = X.iloc[tr], X.iloc[te]; ytr, yte = y[tr], y[te]\n",
    "            pipe = Pipeline([(\"pre\", pre), (\"clf\", clf)]).fit(Xtr, ytr)\n",
    "            proba = pipe.predict_proba(Xte)[:,1]; pred = (proba>=0.5).astype(int)\n",
    "            aucs.append(_safe_auc(yte, proba)); f1s.append(float(f1_score(yte, pred))); briers.append(_safe_brier(yte, proba))\n",
    "        return {\"auc\": float(np.nanmean(aucs)), \"f1\": float(np.nanmean(f1s)), \"brier\": float(np.nanmean(briers))}\n",
    "\n",
    "    def _eval_nlp(self, df: pd.DataFrame, text_col: str, target: str, folds: int) -> Dict[str, Any]:\n",
    "        from sklearn.model_selection import StratifiedKFold\n",
    "        from sklearn.metrics import f1_score, accuracy_score\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        y = df[target].values\n",
    "        texts = df[text_col].astype(str).tolist()\n",
    "        class_counts = pd.Series(y).value_counts()\n",
    "        if len(class_counts)==1 or int(class_counts.min()) < 2:\n",
    "            tr_idx = int(len(texts)*0.8)\n",
    "            vec = TfidfVectorizer(max_features=20000)\n",
    "            X = vec.fit_transform(texts)\n",
    "            Xtr, Xte = X[:tr_idx], X[tr_idx:]\n",
    "            ytr, yte = y[:tr_idx], y[tr_idx:]\n",
    "            clf = LogisticRegression(max_iter=300).fit(Xtr, ytr)\n",
    "            pred = clf.predict(Xte)\n",
    "            return {\"accuracy\": float(accuracy_score(y[tr_idx:], pred)), \"f1\": float(f1_score(y[tr_idx:], pred))}\n",
    "        n_folds = min(folds, max(2, int(class_counts.min())))\n",
    "        skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=self.seed)\n",
    "        accs=[]; f1s=[]\n",
    "        for tr, te in skf.split(texts, y):\n",
    "            vec = TfidfVectorizer(max_features=20000)\n",
    "            Xtr = vec.fit_transform([texts[i] for i in tr])\n",
    "            Xte = vec.transform([texts[i] for i in te])\n",
    "            clf = LogisticRegression(max_iter=300).fit(Xtr, y[tr])\n",
    "            pred = clf.predict(Xte)\n",
    "            accs.append(float(accuracy_score(y[te], pred))); f1s.append(float(f1_score(y[te], pred)))\n",
    "        return {\"accuracy\": float(np.mean(accs)), \"f1\": float(np.mean(f1s))}\n",
    "\n",
    "    def _write_report(self, path: Path, track: str, pre: Dict[str,Any], post: Dict[str,Any], extra: Dict[str,Any]):\n",
    "        html = f\"\"\"<!doctype html><html><head><meta charset='utf-8'><title>Datacrine Report – {track}</title>\n",
    "        <style>body{{font-family:system-ui;margin:2rem}} .k{{font-weight:600}} table{{border-collapse:collapse}} td,th{{border:1px solid #ddd;padding:6px}}</style>\n",
    "        </head><body>\n",
    "        <h1>Datacrine Report – {track}</h1>\n",
    "        <p><span class='k'>Pre metrics:</span> {json.dumps(pre)}</p>\n",
    "        <p><span class='k'>Post metrics:</span> {json.dumps(post)}</p>\n",
    "        <p><span class='k'>Deltas:</span> {json.dumps(extra)}</p>\n",
    "        </body></html>\"\"\"\n",
    "        Path(path).write_text(html, encoding=\"utf-8\")\n",
    "'''\n",
    "module_path.write_text(module_src, encoding=\"utf-8\")\n",
    "module_path.resolve()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "110b2cec-be22-4ec5-a047-ee33ac9e67a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 7: LLM/Embedding utilities (local-first, API-free) ===\n",
    "# Tries a small local embedding model if available; otherwise falls back to TF-IDF.\n",
    "# No internet calls are made here.\n",
    "\n",
    "import numpy as np, pandas as pd, re, hashlib\n",
    "from typing import Optional, Dict, Any, List\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def _maybe_load_embedder(model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "    \"\"\"\n",
    "    Try to load a local SentenceTransformer; if unavailable, return None.\n",
    "    Fallbacks to TF-IDF in calling functions. No downloads attempted.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        # This will only work if the model is already present locally.\n",
    "        return SentenceTransformer(model_name)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def embed_texts(texts: List[str], embedder=None):\n",
    "    \"\"\"\n",
    "    Return (matrix, backend_name). If embedder is None, use TF-IDF sparse matrix.\n",
    "    \"\"\"\n",
    "    if embedder is None:\n",
    "        embedder = _maybe_load_embedder()\n",
    "    if embedder is not None:\n",
    "        E = embedder.encode(texts, normalize_embeddings=True)\n",
    "        return E, \"sbert\"\n",
    "    # Fallback: TF-IDF (dense)\n",
    "    vec = TfidfVectorizer(max_features=50000)\n",
    "    X = vec.fit_transform(texts)\n",
    "    # L2-normalize rows for fair cosine\n",
    "    norms = np.sqrt((X.power(2)).sum(axis=1)).A.ravel() + 1e-12\n",
    "    X = X.multiply(1.0 / norms[:, None])\n",
    "    return X, \"tfidf\"\n",
    "\n",
    "def semantic_near_dup_mask(texts: List[str], threshold: float = 0.92, embedder=None):\n",
    "    \"\"\"\n",
    "    Returns a boolean mask of which rows to KEEP (True = keep).\n",
    "    We treat a text as near-duplicate if cosine(sim) >= threshold with an earlier kept item.\n",
    "    \"\"\"\n",
    "    E, backend = embed_texts(texts, embedder=embedder)\n",
    "    S = cosine_similarity(E, E)\n",
    "    n = len(texts)\n",
    "    keep = np.ones(n, dtype=bool)\n",
    "    kept_indices = []\n",
    "    for i in range(n):\n",
    "        # compare against previously kept items only (greedy)\n",
    "        if not kept_indices:\n",
    "            kept_indices.append(i); continue\n",
    "        sim_to_kept = S[i, kept_indices]\n",
    "        if sim_to_kept.max() >= threshold:\n",
    "            keep[i] = False\n",
    "        else:\n",
    "            kept_indices.append(i)\n",
    "    return keep, backend\n",
    "\n",
    "def label_contradiction_flags(texts: List[str], labels: np.ndarray, embedder=None, margin: float = 0.05):\n",
    "    \"\"\"\n",
    "    Flags suspected mislabels via class-centroid similarity.\n",
    "    If similarity to another class exceeds own-class similarity by > margin → flag True.\n",
    "    \"\"\"\n",
    "    E, backend = embed_texts(texts, embedder=embedder)\n",
    "    classes = np.unique(labels)\n",
    "    # build centroids\n",
    "    centroids = {}\n",
    "    for c in classes:\n",
    "        idx = np.where(labels == c)[0]\n",
    "        if hasattr(E, \"mean\"):  # numpy dense\n",
    "            centroids[c] = E[idx].mean(axis=0)\n",
    "        else:  # sparse\n",
    "            centroids[c] = E[idx].mean(axis=0)\n",
    "\n",
    "    susp = np.zeros(len(labels), dtype=bool)\n",
    "    for i in range(len(labels)):\n",
    "        own = labels[i]\n",
    "        sims = {}\n",
    "        for c in classes:\n",
    "            if hasattr(E, \"dot\"):  # sparse matrix\n",
    "                sims[c] = float(E[i].dot(centroids[c].T))\n",
    "            else:\n",
    "                sims[c] = float(np.dot(E[i], centroids[c]) / (np.linalg.norm(E[i]) * (np.linalg.norm(centroids[c])+1e-12) + 1e-12))\n",
    "        own_sim = sims[own]\n",
    "        best_other = max(v for k, v in sims.items() if k != own)\n",
    "        if best_other > own_sim + margin:\n",
    "            susp[i] = True\n",
    "    return susp, backend\n",
    "\n",
    "def suggest_aliases(categories: pd.Series, min_support: int = 3):\n",
    "    \"\"\"\n",
    "    Simple alias suggester: lowercased normalized forms → canonical.\n",
    "    Groups by [letters+spaces], proposes the most frequent canonical as the alias target.\n",
    "    \"\"\"\n",
    "    norm = categories.astype(str).str.lower().str.replace(r\"[^a-z0-9 ]+\", \"\", regex=True).str.strip()\n",
    "    df = pd.DataFrame({\"orig\": categories, \"norm\": norm})\n",
    "    # collect variants per normalized key\n",
    "    groups = df.groupby(\"norm\")[\"orig\"].value_counts()\n",
    "    suggestions = {}\n",
    "    for norm_key, sub in groups.groupby(level=0):\n",
    "        # choose most frequent original as canonical\n",
    "        variants = sub.droplevel(0)\n",
    "        if variants.sum() >= min_support:\n",
    "            canonical = variants.idxmax()\n",
    "            variants_set = set(variants.index)\n",
    "            suggestions[norm_key] = {\"canonical\": canonical, \"variants\": sorted(variants_set)}\n",
    "    return suggestions  # mapping of normalized group → {canonical, variants}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f57d5c1-fb26-46d3-9d8f-ce492a62854f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM/embedding integration enabled: semantic dedup (NLP), label QA (NLP), alias suggest (tabular).\n"
     ]
    }
   ],
   "source": [
    "# === Cell 8: Patch configs + integrate LLM/embedding ops into DatacrineMachine ===\n",
    "\n",
    "# 1) Extend configs (add LLM flags) without breaking old code\n",
    "ConfigTabular.__annotations__.update({\n",
    "    \"use_llm_alias_suggest\": bool,\n",
    "    \"alias_min_support\": int\n",
    "})\n",
    "if not hasattr(ConfigTabular, \"use_llm_alias_suggest\"):\n",
    "    ConfigTabular.use_llm_alias_suggest = False\n",
    "    ConfigTabular.alias_min_support = 3\n",
    "\n",
    "ConfigNLP.__annotations__.update({\n",
    "    \"use_llm_semantic_dedup\": bool,\n",
    "    \"semantic_threshold\": float,\n",
    "    \"use_llm_label_qa\": bool, \n",
    "    \"label_margin\": float\n",
    "})\n",
    "if not hasattr(ConfigNLP, \"use_llm_semantic_dedup\"):\n",
    "    ConfigNLP.use_llm_semantic_dedup = False\n",
    "    ConfigNLP.semantic_threshold = 0.92\n",
    "    ConfigNLP.use_llm_label_qa = False\n",
    "    ConfigNLP.label_margin = 0.05\n",
    "\n",
    "# 2) Patch DatacrineMachine.run_tabular to add alias suggestions (logged, not auto-applied)\n",
    "_orig_run_tabular = DatacrineMachine.run_tabular\n",
    "def _run_tabular_llm(self, csv_path: str, cfg: ConfigTabular) -> Result:\n",
    "    res = _orig_run_tabular(self, csv_path, cfg)\n",
    "    # LLM alias suggestions (tabular): propose canonical categories per column\n",
    "    if cfg.use_llm_alias_suggest and cfg.category_alias_map is None:\n",
    "        df = res.cleaned_df.copy()\n",
    "        alias_rows = []\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == object:\n",
    "                sugg = suggest_aliases(df[col], min_support=cfg.alias_min_support)\n",
    "                for norm_key, info in sugg.items():\n",
    "                    alias_rows.append({\n",
    "                        \"column\": col,\n",
    "                        \"normalized_key\": norm_key,\n",
    "                        \"proposed_canonical\": info[\"canonical\"],\n",
    "                        \"variants\": \"|\".join(info[\"variants\"])\n",
    "                    })\n",
    "        if alias_rows:\n",
    "            # write to artifacts as alias suggestions file\n",
    "            outdir = Path(res.artifacts[\"cleaned\"]).parent\n",
    "            alias_path = outdir / \"alias_suggestions.csv\"\n",
    "            pd.DataFrame(alias_rows).to_csv(alias_path, index=False)\n",
    "            # also add a meta “edit” (not applied) so it shows up in the ledger\n",
    "            with open(res.artifacts[\"edits\"], \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "                import csv as _csv\n",
    "                w = _csv.writer(f)\n",
    "                for r in alias_rows[:1000]:\n",
    "                    w.writerow([\"—\", r[\"column\"], \"llm_alias_suggest\", \"—\", r[\"proposed_canonical\"], \"suggested alias (not applied)\", f\"{0.80:.2f}\"])\n",
    "            res.artifacts[\"alias_suggestions\"] = str(alias_path)\n",
    "    return res\n",
    "DatacrineMachine.run_tabular = _run_tabular_llm\n",
    "\n",
    "# 3) Patch DatacrineMachine.run_nlp to add semantic dedup + label QA (both logged; dedup can be applied)\n",
    "_orig_run_nlp = DatacrineMachine.run_nlp\n",
    "def _run_nlp_llm(self, csv_path: str, cfg: ConfigNLP) -> Result:\n",
    "    # load raw\n",
    "    df_raw = pd.read_csv(csv_path)\n",
    "    df = df_raw.copy()\n",
    "    outdir = self.artifacts_dir / \"imdb\"\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "    edits = EditLog(outdir / \"edits.csv\")  # temporary ledger for LLM ops here; main runner will append too\n",
    "\n",
    "    # --- LLM semantic de-dup (optional, applied BEFORE base cleaning) ---\n",
    "    if cfg.use_llm_semantic_dedup:\n",
    "        keep, backend = semantic_near_dup_mask(df[cfg.text_col].astype(str).tolist(),\n",
    "                                               threshold=cfg.semantic_threshold,\n",
    "                                               embedder=None)  # local-only; tries SBERT else TF-IDF\n",
    "        dropped_idx = np.where(~keep)[0].tolist()\n",
    "        if dropped_idx:\n",
    "            for idx in dropped_idx[:1000]:\n",
    "                edits.write({\"text\": df.at[idx, cfg.text_col]}, cfg.text_col, \"llm_semantic_dup_drop\",\n",
    "                            \"cosine>=%.2f\"%cfg.semantic_threshold, \"—\",\n",
    "                            f\"semantic dup ({backend})\", 0.90)\n",
    "            df = df.loc[keep].reset_index(drop=True)\n",
    "\n",
    "        # Store a small sidecar file of duplicate indices for transparency\n",
    "        side = pd.DataFrame({\"dropped_index\": dropped_idx})\n",
    "        side_path = outdir / \"semantic_dups.csv\"\n",
    "        side.to_csv(side_path, index=False)\n",
    "\n",
    "    # --- LLM label QA (optional, flags only; NOT auto-changing labels) ---\n",
    "    if cfg.use_llm_label_qa and cfg.target in df.columns:\n",
    "        flags, backend = label_contradiction_flags(\n",
    "            df[cfg.text_col].astype(str).tolist(), df[cfg.target].values, embedder=None, margin=cfg.label_margin\n",
    "        )\n",
    "        flagged = np.where(flags)[0].tolist()\n",
    "        if flagged:\n",
    "            for idx in flagged[:1000]:\n",
    "                edits.write({cfg.text_col: df.at[idx, cfg.text_col], cfg.target: df.at[idx, cfg.target]},\n",
    "                            cfg.target, \"llm_label_contradiction\", df.at[idx, cfg.target], df.at[idx, cfg.target],\n",
    "                            f\"flag only (centroid {backend})\", 0.70)\n",
    "            # Save flags to a sidecar file\n",
    "            flag_path = outdir / \"label_flags.csv\"\n",
    "            pd.DataFrame({\"row_index\": flagged}).to_csv(flag_path, index=False)\n",
    "\n",
    "    # Save the LLM-phase edits, but don't lose the standard pipeline outputs\n",
    "    _ = edits.save()\n",
    "\n",
    "    # Proceed with the original base NLP pipeline (normalize, hash-dedup, eval, report)\n",
    "    res = _orig_run_nlp(self, csv_path, cfg)\n",
    "\n",
    "    # If we pre-applied semantic dedup/flags to a temporary df, reflect counts in the report footer\n",
    "    # (We avoid mutating res.cleaned_df to keep base pipeline deterministic unless flags set)\n",
    "    # Just add notes into artifacts dict for clarity:\n",
    "    if cfg.use_llm_semantic_dedup:\n",
    "        res.artifacts[\"semantic_dups\"] = str(outdir / \"semantic_dups.csv\")\n",
    "    if cfg.use_llm_label_qa:\n",
    "        res.artifacts[\"label_flags\"] = str(outdir / \"label_flags.csv\") if (outdir / \"label_flags.csv\").exists() else \"\"\n",
    "\n",
    "    return res\n",
    "DatacrineMachine.run_nlp = _run_nlp_llm\n",
    "\n",
    "print(\"LLM/embedding integration enabled: semantic dedup (NLP), label QA (NLP), alias suggest (tabular).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedf0cf1-4f4a-4211-92f4-841ee045e998",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
