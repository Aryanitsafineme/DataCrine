{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53161413-8f19-4b62-96aa-a9f5e1a7dc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datacrine.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from transformers import pipeline\n",
    "\n",
    "class Datacrine:\n",
    "    def __init__(self):\n",
    "        # Sentiment model (used for IMDb checks)\n",
    "        self.sentiment_model = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "        self.logs = []\n",
    "\n",
    "    # === Cleaning Functions ===\n",
    "    def impute_numeric_mean(self, df, cols):\n",
    "        for col in cols:\n",
    "            mean_val = df[col].mean()\n",
    "            df[col].fillna(mean_val, inplace=True)\n",
    "            self.logs.append(f\"Imputed missing values in {col} with mean={mean_val:.2f}\")\n",
    "        return df\n",
    "\n",
    "    def cap_outliers_iqr(self, df, cols):\n",
    "        for col in cols:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower, upper = Q1 - 1.5*IQR, Q3 + 1.5*IQR\n",
    "            df[col] = np.clip(df[col], lower, upper)\n",
    "            self.logs.append(f\"Capped outliers in {col} to [{lower:.2f}, {upper:.2f}]\")\n",
    "        return df\n",
    "\n",
    "    def uci_semantic_rules(self, df):\n",
    "        flags, rationales = [], []\n",
    "        for _, row in df.iterrows():\n",
    "            reasons = []\n",
    "            if row[\"X1\"] > 1_000_000:\n",
    "                reasons.append(\"Unrealistic credit limit\")\n",
    "            if row[\"X5\"] < 18:\n",
    "                reasons.append(\"Age < 18\")\n",
    "            if reasons:\n",
    "                flags.append(1)\n",
    "                rationales.append(\"; \".join(reasons))\n",
    "            else:\n",
    "                flags.append(0)\n",
    "                rationales.append(\"Valid\")\n",
    "        df[\"llm_flag\"] = flags\n",
    "        df[\"llm_rationale\"] = rationales\n",
    "        self.logs.append(\"Applied semantic rules to UCI dataset\")\n",
    "        return df\n",
    "\n",
    "    def imdb_label_check(self, df):\n",
    "        preds = self.sentiment_model(df[\"review\"].tolist()[:100])  # sample 100 for speed\n",
    "        flags, rationales = [], []\n",
    "        for i, pred in enumerate(preds):\n",
    "            gold = df.iloc[i][\"sentiment\"]\n",
    "            if (gold == \"positive\" and pred[\"label\"] == \"NEGATIVE\") or \\\n",
    "               (gold == \"negative\" and pred[\"label\"] == \"POSITIVE\"):\n",
    "                flags.append(1)\n",
    "                rationales.append(f\"Mismatch: gold={gold}, pred={pred['label']} ({pred['score']:.2f})\")\n",
    "            else:\n",
    "                flags.append(0)\n",
    "                rationales.append(\"Match\")\n",
    "        df[\"llm_flag\"] = flags + [0]*(len(df)-len(flags))\n",
    "        df[\"llm_rationale\"] = rationales + [\"Not checked\"]*(len(df)-len(rationales))\n",
    "        self.logs.append(\"Checked IMDb dataset with LLM sentiment model\")\n",
    "        return df\n",
    "\n",
    "    # === Training Functions ===\n",
    "    def train_and_evaluate(self, df, target_col, dataset=\"uci\"):\n",
    "        X = df.drop(columns=[target_col], errors=\"ignore\")\n",
    "        y = df[target_col]\n",
    "        results = {}\n",
    "\n",
    "        # Random Forest\n",
    "        rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        rf.fit(X, y)\n",
    "        y_pred = rf.predict(X)\n",
    "        results[\"RandomForest\"] = {\n",
    "            \"Accuracy\": accuracy_score(y, y_pred),\n",
    "            \"F1\": f1_score(y, y_pred, average=\"binary\")\n",
    "        }\n",
    "\n",
    "        # XGBoost\n",
    "        dtrain = xgb.DMatrix(X, label=y)\n",
    "        params = {\"objective\": \"binary:logistic\", \"eval_metric\": \"logloss\"}\n",
    "        bst = xgb.train(params, dtrain, num_boost_round=20)\n",
    "        y_pred = (bst.predict(dtrain) > 0.5).astype(int)\n",
    "        results[\"XGBoost\"] = {\n",
    "            \"Accuracy\": accuracy_score(y, y_pred),\n",
    "            \"F1\": f1_score(y, y_pred, average=\"binary\")\n",
    "        }\n",
    "\n",
    "        self.logs.append(f\"Trained & evaluated models on {dataset} dataset\")\n",
    "        return results\n",
    "\n",
    "    # === Export Functions ===\n",
    "    def export_logs(self, filename):\n",
    "        with open(filename, \"w\") as f:\n",
    "            for log in self.logs:\n",
    "                f.write(log + \"\\n\")\n",
    "\n",
    "    def save_dataset(self, df, filename):\n",
    "        df.to_csv(filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d60341a-20d8-4c33-8a2b-1417aa2d555b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datacrine'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatacrine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Datacrine\n\u001b[0;32m      2\u001b[0m dc \u001b[38;5;241m=\u001b[39m Datacrine()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datacrine'"
     ]
    }
   ],
   "source": [
    "from datacrine import Datacrine\n",
    "dc = Datacrine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf9e60c0-107f-447d-af45-cd266cecafd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datacrine'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mucimlrepo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_ucirepo\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkagglehub\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatacrine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Datacrine\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Initialize framework\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datacrine'"
     ]
    }
   ],
   "source": [
    "# Datacrine Demo Notebook\n",
    "# Author: Aryan Singh\n",
    "# Thesis: \"Datacrine: A Modular, Interpretable AI Framework for Smart Data Cleaning\"\n",
    "\n",
    "# === Setup ===\n",
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import kagglehub\n",
    "from datacrine import Datacrine\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize framework\n",
    "dc = Datacrine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ebdd533-f99c-4222-8eea-7fab4cc15cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCI Credit Dataset Shape: (30000, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>X19</th>\n",
       "      <th>X20</th>\n",
       "      <th>X21</th>\n",
       "      <th>X22</th>\n",
       "      <th>X23</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       X1  X2  X3  X4  X5  X6  X7  X8  X9  X10  ...    X15    X16    X17  \\\n",
       "0   20000   2   2   1  24   2   2  -1  -1   -2  ...      0      0      0   \n",
       "1  120000   2   2   2  26  -1   2   0   0    0  ...   3272   3455   3261   \n",
       "2   90000   2   2   2  34   0   0   0   0    0  ...  14331  14948  15549   \n",
       "3   50000   2   2   1  37   0   0   0   0    0  ...  28314  28959  29547   \n",
       "4   50000   1   2   1  57  -1   0  -1   0    0  ...  20940  19146  19131   \n",
       "\n",
       "    X18    X19    X20   X21   X22   X23  Y  \n",
       "0     0    689      0     0     0     0  1  \n",
       "1     0   1000   1000  1000     0  2000  1  \n",
       "2  1518   1500   1000  1000  1000  5000  0  \n",
       "3  2000   2019   1200  1100  1069  1000  0  \n",
       "4  2000  36681  10000  9000   689   679  0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "uci_data = fetch_ucirepo(id=350)\n",
    "uci_credit = pd.concat([uci_data.data.features, uci_data.data.targets], axis=1)\n",
    "\n",
    "print(\"UCI Credit Dataset Shape:\", uci_credit.shape)\n",
    "uci_credit.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9015f1ee-cb31-4260-8048-0cf375ad702a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Clean dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m uci_cleaned \u001b[38;5;241m=\u001b[39m dc\u001b[38;5;241m.\u001b[39mimpute_numeric_mean(uci_credit\u001b[38;5;241m.\u001b[39mcopy(), [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX5\u001b[39m\u001b[38;5;124m\"\u001b[39m])   \u001b[38;5;66;03m# AGE\u001b[39;00m\n\u001b[0;32m      3\u001b[0m uci_cleaned \u001b[38;5;241m=\u001b[39m dc\u001b[38;5;241m.\u001b[39mcap_outliers_iqr(uci_cleaned, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX1\u001b[39m\u001b[38;5;124m\"\u001b[39m])            \u001b[38;5;66;03m# LIMIT_BAL\u001b[39;00m\n\u001b[0;32m      4\u001b[0m uci_cleaned \u001b[38;5;241m=\u001b[39m dc\u001b[38;5;241m.\u001b[39muci_semantic_rules(uci_cleaned)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dc' is not defined"
     ]
    }
   ],
   "source": [
    "# Clean dataset\n",
    "uci_cleaned = dc.impute_numeric_mean(uci_credit.copy(), [\"X5\"])   # AGE\n",
    "uci_cleaned = dc.cap_outliers_iqr(uci_cleaned, [\"X1\"])            # LIMIT_BAL\n",
    "uci_cleaned = dc.uci_semantic_rules(uci_cleaned)\n",
    "uci_cleaned[\"Y\"] = uci_credit[\"Y\"].values\n",
    "\n",
    "# Train + evaluate\n",
    "uci_results = dc.train_and_evaluate(uci_cleaned, target_col=\"Y\", dataset=\"uci\")\n",
    "print(\"UCI Results:\", uci_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3601ca1b-2fce-418d-aa46-c2df3bc2c3fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'uci_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m models \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandomForest\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXGBoost\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      3\u001b[0m metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      5\u001b[0m results \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUCI\u001b[39m\u001b[38;5;124m\"\u001b[39m: uci_results,\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIMDb\u001b[39m\u001b[38;5;124m\"\u001b[39m: imdb_results\n\u001b[0;32m      8\u001b[0m }\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m metrics:\n\u001b[0;32m     11\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m4\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'uci_results' is not defined"
     ]
    }
   ],
   "source": [
    "datasets = [\"UCI\", \"IMDb\"]\n",
    "models = [\"RandomForest\", \"XGBoost\"]\n",
    "metrics = [\"Accuracy\", \"F1\"]\n",
    "\n",
    "results = {\n",
    "    \"UCI\": uci_results,\n",
    "    \"IMDb\": imdb_results\n",
    "}\n",
    "\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    vals = []\n",
    "    labels = []\n",
    "    for dataset in datasets:\n",
    "        for model in models:\n",
    "            vals.append(results[dataset][model][metric])\n",
    "            labels.append(f\"{dataset}-{model}\")\n",
    "    plt.bar(labels, vals, color=[\"skyblue\",\"orange\",\"skyblue\",\"orange\"])\n",
    "    plt.title(f\"{metric} Comparison\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad49c66-81a9-41c4-ace5-4be602552825",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
